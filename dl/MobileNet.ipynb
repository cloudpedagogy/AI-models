{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNpB9vISZZoblitA2u6u27d",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cloudpedagogy/models/blob/main/dl/MobileNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# MobileNet Model Background"
      ],
      "metadata": {
        "id": "TJRQnBDR_aXw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MobileNet is a type of neural network architecture specifically designed for efficient deep learning on mobile and embedded devices. It was developed by Google researchers in 2017 to address the need for lightweight and computationally efficient models that can run on resource-constrained platforms without sacrificing too much accuracy.\n",
        "\n",
        "**Pros of MobileNet**:\n",
        "\n",
        "1. Efficiency: MobileNet is known for its small size and low computational requirements, making it ideal for running on devices with limited processing power and memory.\n",
        "\n",
        "2. Speed: Due to its lightweight nature, MobileNet can perform inference quickly, allowing for real-time applications on mobile and embedded devices.\n",
        "\n",
        "3. Low memory footprint: The architecture of MobileNet uses depth-wise separable convolutions, which reduces the number of parameters and memory footprint, enabling it to be deployed on memory-constrained devices.\n",
        "\n",
        "4. Good accuracy-tradeoff: Despite being optimized for efficiency, MobileNet still achieves respectable accuracy on various computer vision tasks like image classification and object detection.\n",
        "\n",
        "5. Pretrained models: Google provides pre-trained versions of MobileNet on large-scale image datasets, allowing developers to fine-tune the models for specific tasks with minimal data.\n",
        "\n",
        "**Cons of MobileNet**:\n",
        "\n",
        "1. Lower accuracy compared to larger models: As a tradeoff for efficiency, MobileNet might not achieve the same accuracy as deeper and more complex networks like ResNet or VGG on certain tasks, especially when ample computational resources are available.\n",
        "\n",
        "2. Limited capacity: MobileNet's small size and lightweight nature come with the limitation of representing complex patterns and relationships present in some datasets.\n",
        "\n",
        "3. Task-specific tuning: While MobileNet's pre-trained models can be a good starting point, achieving optimal performance might require fine-tuning the network on your specific dataset, which can be time-consuming.\n",
        "\n",
        "**When to use MobileNet**:\n",
        "\n",
        "MobileNet is an excellent choice under the following scenarios:\n",
        "\n",
        "1. Mobile and Embedded Devices: When you need to deploy a deep learning model on resource-constrained devices like smartphones, IoT devices, or edge devices, MobileNet's efficiency becomes crucial.\n",
        "\n",
        "2. Real-time Applications: MobileNet's fast inference speed makes it well-suited for applications that require real-time processing, such as real-time object detection, image classification, or facial recognition.\n",
        "\n",
        "3. Prototyping and Rapid Deployment: During the initial stages of development or when quick deployment is needed, MobileNet's pre-trained models can serve as a good starting point, saving time and resources.\n",
        "\n",
        "4. Transfer Learning: If you have a limited amount of data for your specific task, starting with a pre-trained MobileNet model and fine-tuning it on your dataset can often yield good results.\n",
        "\n",
        "However, if you have access to more powerful hardware and have sufficient computational resources, it might be worth exploring larger and more complex models for improved accuracy on your specific task. It's essential to strike the right balance between efficiency and performance based on the requirements of your application."
      ],
      "metadata": {
        "id": "oXkcMbbbBgS-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code Example"
      ],
      "metadata": {
        "id": "uLlkJmOu1irc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "def MobileNetV1(input_shape=(224, 224, 3), num_classes=1000):\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), strides=(2, 2), padding='same', activation='relu', input_shape=input_shape))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    model.add(tf.keras.layers.DepthwiseConv2D((3, 3), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Conv2D(64, (1, 1), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    model.add(tf.keras.layers.DepthwiseConv2D((3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Conv2D(128, (1, 1), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    model.add(tf.keras.layers.DepthwiseConv2D((3, 3), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Conv2D(128, (1, 1), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    model.add(tf.keras.layers.DepthwiseConv2D((3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Conv2D(256, (1, 1), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    model.add(tf.keras.layers.DepthwiseConv2D((3, 3), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Conv2D(256, (1, 1), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    model.add(tf.keras.layers.DepthwiseConv2D((3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Conv2D(512, (1, 1), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    for _ in range(5):\n",
        "        model.add(tf.keras.layers.DepthwiseConv2D((3, 3), padding='same', activation='relu'))\n",
        "        model.add(tf.keras.layers.BatchNormalization())\n",
        "        model.add(tf.keras.layers.Conv2D(512, (1, 1), padding='same', activation='relu'))\n",
        "        model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    model.add(tf.keras.layers.DepthwiseConv2D((3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Conv2D(1024, (1, 1), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "    model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "# Create the MobileNetV1 model\n",
        "model = MobileNetV1()\n",
        "\n",
        "# Display model summary\n",
        "model.summary()\n"
      ],
      "metadata": {
        "id": "89qRBgMhjt0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code breakdown"
      ],
      "metadata": {
        "id": "J-5BCkXD1m3Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Import TensorFlow:\n",
        "```python\n",
        "import tensorflow as tf\n",
        "```\n",
        "\n",
        "2. Define the MobileNetV1 function:\n",
        "```python\n",
        "def MobileNetV1(input_shape=(224, 224, 3), num_classes=1000):\n",
        "    model = tf.keras.Sequential()\n",
        "```\n",
        "The function `MobileNetV1` takes two optional arguments: `input_shape` (default: (224, 224, 3)) specifies the input image size, and `num_classes` (default: 1000) is the number of classes for classification.\n",
        "\n",
        "3. Add initial layers to the model:\n",
        "```python\n",
        "    model.add(tf.keras.layers.Conv2D(32, (3, 3), strides=(2, 2), padding='same', activation='relu', input_shape=input_shape))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "```\n",
        "The first layer is a `Conv2D` layer with 32 filters, a kernel size of (3, 3), and a stride of (2, 2). The activation function used is ReLU. This layer is followed by a `BatchNormalization` layer, which helps in improving the training stability and accelerating convergence.\n",
        "\n",
        "4. Add multiple depthwise separable convolution blocks:\n",
        "```python\n",
        "    model.add(tf.keras.layers.DepthwiseConv2D((3, 3), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Conv2D(64, (1, 1), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    model.add(tf.keras.layers.DepthwiseConv2D((3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Conv2D(128, (1, 1), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    # More depthwise separable convolution blocks...\n",
        "\n",
        "    for _ in range(5):\n",
        "        model.add(tf.keras.layers.DepthwiseConv2D((3, 3), padding='same', activation='relu'))\n",
        "        model.add(tf.keras.layers.BatchNormalization())\n",
        "        model.add(tf.keras.layers.Conv2D(512, (1, 1), padding='same', activation='relu'))\n",
        "        model.add(tf.keras.layers.BatchNormalization())\n",
        "```\n",
        "These blocks consist of a depthwise convolution layer, followed by a batch normalization layer, and then a pointwise convolution (1x1 Conv2D) layer. Depthwise separable convolutions reduce the number of parameters and computational complexity while maintaining the model's representational power.\n",
        "\n",
        "5. Add the final layers to the model:\n",
        "```python\n",
        "    model.add(tf.keras.layers.DepthwiseConv2D((3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "    model.add(tf.keras.layers.Conv2D(1024, (1, 1), padding='same', activation='relu'))\n",
        "    model.add(tf.keras.layers.BatchNormalization())\n",
        "\n",
        "    model.add(tf.keras.layers.GlobalAveragePooling2D())\n",
        "    model.add(tf.keras.layers.Dense(num_classes, activation='softmax'))\n",
        "```\n",
        "The final part of the model includes one more depthwise separable convolution block, followed by global average pooling over the spatial dimensions. The global average pooling reduces the spatial dimensions of the output to 1x1, after which a `Dense` layer with `num_classes` units and softmax activation is used for classification.\n",
        "\n",
        "6. Return the model:\n",
        "```python\n",
        "    return model\n",
        "```\n",
        "\n",
        "7. Create the MobileNetV1 model:\n",
        "```python\n",
        "model = MobileNetV1()\n",
        "```\n",
        "\n",
        "8. Display model summary:\n",
        "```python\n",
        "model.summary()\n",
        "```\n",
        "The `model.summary()` method provides a summary of the model's architecture, including layer types, output shapes, and the number of trainable parameters.\n",
        "\n",
        "Overall, the code defines the MobileNetV1 model architecture, a popular lightweight CNN suitable for resource-constrained environments like mobile devices or edge devices. The model is designed for image classification tasks with `num_classes` classes."
      ],
      "metadata": {
        "id": "CpLu0Hl5wEU6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Real world application"
      ],
      "metadata": {
        "id": "Ew_lajCJ2lyb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "MobileNet is a lightweight and efficient convolutional neural network architecture designed for mobile and embedded vision applications. Its small size and low computational requirements make it suitable for resource-constrained environments, including healthcare settings. One real-world example of using MobileNet in the healthcare industry is for skin lesion classification in dermatology.\n",
        "\n",
        "Skin cancer is a prevalent form of cancer, and early detection is crucial for successful treatment. Dermatologists often use dermoscopy, a non-invasive imaging technique, to capture images of skin lesions. These images can then be classified into different categories, such as benign, malignant, or suspicious, to assist in diagnosis.\n",
        "\n",
        "Here's how MobileNet can be utilized for skin lesion classification:\n",
        "\n",
        "1. **Data Collection:** Dermoscopic images of skin lesions are collected from patients, along with corresponding labels indicating the lesion's category (e.g., benign, malignant, or suspicious).\n",
        "\n",
        "2. **Data Preprocessing:** The images are preprocessed to ensure uniformity in size and format. This step involves resizing the images to a specific resolution and normalizing pixel values.\n",
        "\n",
        "3. **Model Selection:** MobileNet is chosen as the base model due to its efficiency and lightweight nature. The pre-trained MobileNet model is often used as a feature extractor or fine-tuned for this specific task.\n",
        "\n",
        "4. **Transfer Learning:** Transfer learning is employed by using the pre-trained MobileNet model with weights learned from a large dataset (e.g., ImageNet). The model's final classification layers are modified or replaced to suit the skin lesion classification task.\n",
        "\n",
        "5. **Data Augmentation:** To augment the dataset and prevent overfitting, data augmentation techniques like random rotation, flipping, and scaling can be applied to the images.\n",
        "\n",
        "6. **Training:** The modified MobileNet model is trained on the preprocessed dermoscopy images with their corresponding labels. The objective is to minimize the classification loss and improve the model's accuracy.\n",
        "\n",
        "7. **Model Evaluation:** The trained MobileNet model is evaluated on a separate test dataset to assess its performance. Common evaluation metrics include accuracy, precision, recall, and F1-score.\n",
        "\n",
        "8. **Deployment:** Once the model demonstrates satisfactory performance, it can be deployed to assist dermatologists in real-world clinical settings. Dermatologists can use a mobile app or a web-based interface to upload dermoscopy images, and the model can quickly classify the lesions as benign, malignant, or suspicious, aiding in the diagnostic process.\n",
        "\n",
        "By using MobileNet for skin lesion classification, healthcare providers can enhance the efficiency and accessibility of skin cancer screening, particularly in regions with limited access to dermatologists. The model's lightweight nature allows it to run on mobile devices, making it a practical and potentially life-saving tool in the healthcare industry. However, it is essential to ensure that the model is thoroughly evaluated and validated before its clinical deployment to guarantee its reliability and accuracy."
      ],
      "metadata": {
        "id": "QvVa0qwJEcs9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FAQ"
      ],
      "metadata": {
        "id": "htKLb2Dg4MdH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **What is MobileNet?**\n",
        "MobileNet is a family of deep neural network architectures developed by Google. It is designed to be lightweight and efficient, making it ideal for running on resource-constrained devices such as smartphones and embedded systems.\n",
        "\n",
        "2. **Why is MobileNet considered \"mobile\"?**\n",
        "MobileNet is called \"mobile\" because of its small size and computational efficiency. It is designed to have a small number of parameters and operations, allowing it to run smoothly on mobile devices with limited processing power and memory.\n",
        "\n",
        "3. **How does MobileNet achieve its efficiency?**\n",
        "MobileNet achieves its efficiency through two key techniques: depthwise separable convolutions and pointwise convolutions. Depthwise separable convolutions split the standard convolution into depthwise and pointwise convolutions, reducing computational complexity. Pointwise convolutions are 1x1 convolutions used for dimensionality reduction.\n",
        "\n",
        "4. **What are the applications of MobileNet?**\n",
        "MobileNet can be used for various computer vision tasks such as image classification, object detection, face recognition, style transfer, and more. Its efficiency makes it suitable for real-time and on-device applications.\n",
        "\n",
        "5. **How does MobileNet compare to other deep learning models?**\n",
        "Compared to traditional deep learning models like VGG and ResNet, MobileNet has a significantly smaller memory footprint and requires fewer computations, making it faster and more suitable for mobile and embedded devices.\n",
        "\n",
        "6. **What are the different versions of MobileNet?**\n",
        "MobileNet has multiple versions, each optimized for different use cases. Some of the popular versions include MobileNetV1, MobileNetV2, and MobileNetV3. MobileNetV2 introduced inverted residuals and linear bottlenecks, while MobileNetV3 further improved performance by introducing h-swish activation and SE (Squeeze-and-Excitation) blocks.\n",
        "\n",
        "7. **Can MobileNet be used on non-mobile devices?**\n",
        "Yes, MobileNet can be used on non-mobile devices as well. While its primary advantage lies in its efficiency on mobile and embedded platforms, it can also be deployed on other devices for various computer vision tasks.\n",
        "\n",
        "8. **Is transfer learning effective with MobileNet?**\n",
        "Yes, transfer learning with MobileNet is effective. MobileNet models are often pretrained on large-scale datasets like ImageNet. You can use these pretrained models as a starting point for fine-tuning on your specific task, even if you have limited data.\n",
        "\n",
        "9. **What programming frameworks support MobileNet?**\n",
        "MobileNet models are available in popular deep learning frameworks like TensorFlow, Keras, and PyTorch, making it accessible to a wide range of developers and researchers.\n",
        "\n",
        "10. **Does MobileNet sacrifice accuracy for efficiency?**\n",
        "While MobileNet is designed to be efficient, it does not sacrifice accuracy significantly. It may have slightly lower accuracy compared to larger and more computationally intensive models, but it still performs remarkably well on various tasks, especially given its small size and efficiency.\n",
        "\n",
        "Remember that the specifics of MobileNet might change as new versions or improvements are released, so it's always a good idea to refer to the latest documentation and research papers for the most up-to-date information."
      ],
      "metadata": {
        "id": "JZ09e8PG4ZFH"
      }
    }
  ]
}