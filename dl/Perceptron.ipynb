{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOKfkRqwTA49/LIS9k5eRNz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cloudpedagogy/AI-models/blob/main/dl/Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perceptron Model Background"
      ],
      "metadata": {
        "id": "Kqoi-jiK_yhf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Perceptron is one of the earliest and simplest forms of neural networks, dating back to the late 1950s. It was proposed by Frank Rosenblatt and laid the foundation for modern neural network architectures. The Perceptron is a type of single-layer feedforward neural network, meaning it consists of only one layer of artificial neurons, also known as perceptrons.\n",
        "\n",
        "**Here's how the Perceptron works**:\n",
        "\n",
        "1. **Input Layer**: The Perceptron takes a set of input features, represented as a vector, where each feature is multiplied by a corresponding weight. These weighted inputs are then summed up.\n",
        "\n",
        "2. **Activation Function**: The summed value is then passed through an activation function. Traditionally, a step function was used, but nowadays, other activation functions like the sigmoid or ReLU are more common.\n",
        "\n",
        "3. **Output**: The output of the activation function determines the final output of the Perceptron, usually binary (0 or 1) in the case of a single Perceptron.\n",
        "\n",
        "4. **Learning**: The Perceptron learns by adjusting its weights based on the error generated by comparing its output to the desired output. The process is called the Perceptron learning rule and is based on the concept of supervised learning.\n",
        "\n",
        "**Pros of Perceptron**:\n",
        "1. Simplicity: Perceptrons are straightforward and easy to understand, making them a good starting point for learning about neural networks.\n",
        "2. Fast Training: Due to their simplicity, training a Perceptron is relatively fast compared to more complex neural networks.\n",
        "3. Good for Linear Separability: Perceptrons work well for problems that are linearly separable, where a single straight line can classify the data.\n",
        "\n",
        "**Cons of Perceptron**:\n",
        "1. Limited Representational Power: The Perceptron can only learn linear decision boundaries, making it unsuitable for problems that require non-linear separation.\n",
        "2. Not Suitable for Complex Tasks: Perceptrons are not capable of handling tasks with high complexity or those that require learning intricate patterns.\n",
        "3. Convergence Issues: The Perceptron learning rule has convergence guarantees only for linearly separable data. In cases where the data is not linearly separable, the learning process might not converge to a solution.\n",
        "\n",
        "**When to use Perceptron**:\n",
        "The Perceptron is mostly used for educational purposes and simple problems where the data is linearly separable. If you have a binary classification problem with easily separable data, a single-layer Perceptron might be sufficient. However, in most real-world scenarios, where data is rarely linearly separable, you'll need more complex neural network architectures like multi-layer perceptrons (MLPs), convolutional neural networks (CNNs), or recurrent neural networks (RNNs) to achieve better performance. These advanced architectures can handle non-linear patterns and complex tasks effectively."
      ],
      "metadata": {
        "id": "Hf6fGgo-66M5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code Example"
      ],
      "metadata": {
        "id": "u-WdsUIKbWOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, input_size, learning_rate=0.1, epochs=100):\n",
        "        self.weights = np.random.rand(input_size)\n",
        "        self.bias = np.random.rand()\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        summation = np.dot(inputs, self.weights) + self.bias\n",
        "        return 1 if summation >= 0 else 0\n",
        "\n",
        "    def train(self, training_data, labels):\n",
        "        for epoch in range(self.epochs):\n",
        "            for inputs, label in zip(training_data, labels):\n",
        "                prediction = self.predict(inputs)\n",
        "                self.weights += self.learning_rate * (label - prediction) * inputs\n",
        "                self.bias += self.learning_rate * (label - prediction)\n",
        "\n",
        "# Example usage with logical OR function\n",
        "data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "labels = np.array([0, 1, 1, 1])\n",
        "\n",
        "# Create and train the Perceptron model\n",
        "input_size = 2\n",
        "perceptron_model = Perceptron(input_size)\n",
        "perceptron_model.train(data, labels)\n",
        "\n",
        "# Test the trained model\n",
        "test_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "for inputs in test_data:\n",
        "    prediction = perceptron_model.predict(inputs)\n",
        "    print(f\"Input: {inputs}, Prediction: {prediction}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "mCxhx4ScEnG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code breakdown"
      ],
      "metadata": {
        "id": "ExxOxfDl1VGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Import libraries: The code starts by importing the required library `numpy` which is used for numerical computations.\n",
        "\n",
        "2. Define the `Perceptron` class: The code defines a class called `Perceptron`, which is a simple implementation of a single-layer perceptron. A perceptron is a basic building block of neural networks.\n",
        "\n",
        "3. Initialize the perceptron: In the `__init__` method of the `Perceptron` class, the perceptron is initialized with random weights and bias. The `input_size` parameter specifies the number of input features, `learning_rate` sets the step size for weight and bias updates during training, and `epochs` sets the number of training iterations.\n",
        "\n",
        "4. Predict method: The `predict` method takes an input array (`inputs`) and calculates the weighted sum of inputs multiplied by the weights (`np.dot(inputs, self.weights)`), adds the bias term, and returns 1 if the summation is greater than or equal to 0, otherwise returns 0. This is a binary prediction based on the sign of the summation.\n",
        "\n",
        "5. Train method: The `train` method is responsible for updating the weights and bias of the perceptron during training. It takes `training_data`, which is a 2D array containing input features, and `labels`, a 1D array with corresponding binary labels (0 or 1).\n",
        "\n",
        "6. Training loop: The `train` method contains a training loop with the number of epochs specified during initialization. It iterates over each epoch and then over each training example. For each example, it calculates the predicted output using the `predict` method, then updates the weights and bias based on the error (difference between the predicted output and the actual label) and the learning rate.\n",
        "\n",
        "7. Example usage with the logical OR function: The code demonstrates the usage of the `Perceptron` class to learn the logical OR function. It defines the logical OR data (`data`) and labels (`labels`) as NumPy arrays.\n",
        "\n",
        "8. Create and train the Perceptron model: It creates a `Perceptron` model with `input_size = 2` (as there are two input features) and trains the model using the `train` method on the provided data and labels.\n",
        "\n",
        "9. Test the trained model: The code tests the trained perceptron by providing test data (`test_data`) and iterating through each input. For each input, it makes a prediction using the `predict` method and prints the input along with the predicted value (0 or 1).\n",
        "\n",
        "This example is a basic implementation of a perceptron for a simple logical OR function, but it showcases the core principles of a single-layer neural network. In practice, perceptrons are used as building blocks for more complex neural network architectures to solve more challenging tasks."
      ],
      "metadata": {
        "id": "KPsAD_PJExFA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Real world application"
      ],
      "metadata": {
        "id": "WhhFu5HS2c7d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's consider a real-world example of using the Perceptron model in a healthcare setting for diagnosing a medical condition based on patient data.\n",
        "\n",
        "**Example: Diagnosing Diabetes using Perceptron**\n",
        "\n",
        "Problem: We want to develop a simple binary classifier using the Perceptron model to predict whether a patient has diabetes or not based on certain medical features.\n",
        "\n",
        "Dataset: We have a dataset containing medical records of patients, where each data point represents a patient and includes the following features:\n",
        "1. Age: The age of the patient.\n",
        "2. BMI: Body Mass Index, a measure of body fat based on weight and height.\n",
        "3. Blood Pressure: The patient's blood pressure.\n",
        "4. Glucose Level: The patient's fasting blood glucose level.\n",
        "5. Insulin Level: The patient's fasting insulin level.\n",
        "6. Diabetes Label: The binary label indicating whether the patient has diabetes (1) or not (0).\n",
        "\n",
        "Model: We'll use a single-layer Perceptron model for binary classification.\n",
        "\n",
        "**Steps:**\n",
        "\n",
        "1. **Data Collection**: Gather the patient data, including age, BMI, blood pressure, glucose level, insulin level, and whether they have diabetes or not (the ground truth label).\n",
        "\n",
        "2. **Data Preprocessing**: Normalize the features to have zero mean and unit variance, which helps the model converge faster. Split the dataset into training and testing sets.\n",
        "\n",
        "3. **Perceptron Model**:\n",
        "   - Initialize the weights and bias with random values.\n",
        "   - Define the activation function (e.g., step function or sigmoid function) to transform the model's output into binary predictions.\n",
        "   - Define the learning rate, which controls how much the weights are updated during each iteration.\n",
        "\n",
        "4. **Training**:\n",
        "   - Iterate through the training set and update the model's weights and bias based on the prediction error.\n",
        "   - The prediction error is calculated as the difference between the predicted label and the true label.\n",
        "   - Adjust the weights and bias using the learning rate and the prediction error.\n",
        "   - Continue training for multiple epochs (passes through the entire training set) to improve the model's performance.\n",
        "\n",
        "5. **Evaluation**:\n",
        "   - After training, use the trained Perceptron model to make predictions on the testing set.\n",
        "   - Compare the model's predictions with the ground truth labels to calculate accuracy, precision, recall, F1 score, etc., to evaluate the model's performance.\n",
        "\n",
        "6. **Inference**:\n",
        "   - Once the model is trained and evaluated, it can be deployed to predict diabetes in new patients.\n",
        "   - Given the medical features of a new patient, pass the data through the trained Perceptron to obtain the predicted label (0 for no diabetes, 1 for diabetes).\n",
        "\n",
        "This real-world example shows how the Perceptron model can be applied in a healthcare setting for diagnosing diabetes based on patient data. Keep in mind that this is a simple example, and in practice, more sophisticated models and extensive data preprocessing would be used to achieve better performance and accuracy in medical diagnosis. Additionally, medical diagnosis involves complex decision-making, and machine learning models should be used with caution, always in conjunction with expert medical knowledge and oversight."
      ],
      "metadata": {
        "id": "aHXgwZKNFk8f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FAQ"
      ],
      "metadata": {
        "id": "-Ru32IH24En-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. What is a Perceptron?\n",
        "   A Perceptron is the simplest form of an artificial neural network, inspired by the biological neurons in the human brain. It consists of a single layer of interconnected nodes (neurons) that can make simple binary decisions.\n",
        "\n",
        "2. Who invented the Perceptron?\n",
        "   The Perceptron was invented by Frank Rosenblatt in 1957 at the Cornell Aeronautical Laboratory, now known as the Cornell University School of Operations Research and Information Engineering.\n",
        "\n",
        "3. How does a Perceptron work?\n",
        "   A Perceptron takes multiple inputs, each with an associated weight. It sums up the weighted inputs and applies an activation function to produce the output. The output is usually binary (0 or 1) based on whether the sum exceeds a certain threshold.\n",
        "\n",
        "4. What is the \"Perceptron Convergence Theorem\"?\n",
        "   The Perceptron Convergence Theorem, proved by Rosenblatt, states that a Perceptron can learn to classify linearly separable patterns correctly if the learning rate is small enough, and the data is linearly separable.\n",
        "\n",
        "5. What are the limitations of a Perceptron?\n",
        "   Perceptrons have some limitations, primarily being able to learn only linearly separable patterns. They cannot handle problems that require more complex decision boundaries or those with overlapping classes.\n",
        "\n",
        "6. How is a Multi-Layer Perceptron (MLP) different from a Perceptron?\n",
        "   Unlike a simple Perceptron, an MLP consists of multiple layers of interconnected nodes, including one or more hidden layers. This allows MLPs to handle more complex patterns and learn non-linear relationships.\n",
        "\n",
        "7. What are some applications of Perceptrons?\n",
        "   Perceptrons were historically used for pattern recognition and binary classification tasks. While they are not commonly used on their own today, their basic principles form the foundation of more advanced neural network architectures used in various applications like image recognition, natural language processing, and more.\n",
        "\n",
        "8. Can Perceptrons be used for regression tasks?\n",
        "   No, Perceptrons are primarily used for binary classification tasks. For regression tasks (predicting continuous values), other algorithms like linear regression or more advanced neural networks like MLPs with suitable activation functions are used.\n",
        "\n",
        "9. Are Perceptrons still relevant in modern machine learning?\n",
        "   While the original Perceptron model is not widely used in modern machine learning due to its limitations, the concept of simple neuron units and their role in forming more complex networks is still fundamental to modern deep learning models.\n",
        "\n",
        "10. How did the Perceptron influence the field of artificial intelligence?\n",
        "   The Perceptron was a significant early development in the field of artificial intelligence and neural networks. It played a crucial role in inspiring further research and paved the way for more advanced neural network architectures that emerged in later years."
      ],
      "metadata": {
        "id": "O41fWMkJT07w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quiz"
      ],
      "metadata": {
        "id": "-zJ_EVyJVFuU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "**Question 1:** What is the Perceptron model primarily used for?\n",
        "a) Image generation\n",
        "b) Sentiment analysis\n",
        "c) Speech recognition\n",
        "d) Reinforcement learning\n",
        "\n",
        "**Question 2:** In the context of a Perceptron, what does a weight represent?\n",
        "a) The activation function\n",
        "b) The input feature\n",
        "c) The output label\n",
        "d) The strength of the connection between neurons\n",
        "\n",
        "**Question 3:** The Perceptron model is based on which mathematical concept?\n",
        "a) Calculus\n",
        "b) Statistics\n",
        "c) Linear algebra\n",
        "d) Trigonometry\n",
        "\n",
        "**Question 4:** What is the purpose of the bias term in a Perceptron?\n",
        "a) It determines the learning rate of the model.\n",
        "b) It prevents overfitting.\n",
        "c) It shifts the decision boundary.\n",
        "d) It adds noise to the input data.\n",
        "\n",
        "**Question 5:** How does a Perceptron make a decision based on its inputs?\n",
        "a) By calculating the dot product of inputs and weights.\n",
        "b) By applying a nonlinear activation function to the inputs.\n",
        "c) By sorting the inputs in descending order.\n",
        "d) By directly summing up the inputs.\n",
        "\n",
        "**Question 6:** What happens during the training of a Perceptron?\n",
        "a) Weights are randomly initialized.\n",
        "b) Inputs are passed through the model to make predictions.\n",
        "c) Weights are adjusted to minimize prediction errors.\n",
        "d) The bias term is removed from the model.\n",
        "\n",
        "**Question 7:** Which of the following is a limitation of the basic Perceptron model?\n",
        "a) It can only classify linearly separable data.\n",
        "b) It cannot be trained using gradient descent.\n",
        "c) It requires a large amount of labeled data.\n",
        "d) It doesn't have an activation function.\n",
        "\n",
        "**Question 8:** The Perceptron algorithm updates the weights based on:\n",
        "a) The input data only.\n",
        "b) The output labels only.\n",
        "c) Both the input data and output labels.\n",
        "d) The bias term only.\n",
        "\n",
        "**Question 9:** In the context of a multi-layer Perceptron (MLP), what is the purpose of hidden layers?\n",
        "a) They contain the input features.\n",
        "b) They directly produce the final output.\n",
        "c) They extract and transform features.\n",
        "d) They store the model parameters.\n",
        "\n",
        "**Question 10:** Which famous theorem is associated with the limitations of the Perceptron model for linearly inseparable data?\n",
        "a) Bayes' Theorem\n",
        "b) The Central Limit Theorem\n",
        "c) The Universal Approximation Theorem\n",
        "d) The Perceptron Convergence Theorem\n",
        "\n",
        "**Answers:**\n",
        "1. b) Sentiment analysis\n",
        "2. d) The strength of the connection between neurons\n",
        "3. c) Linear algebra\n",
        "4. c) It shifts the decision boundary.\n",
        "5. a) By calculating the dot product of inputs and weights.\n",
        "6. c) Weights are adjusted to minimize prediction errors.\n",
        "7. a) It can only classify linearly separable data.\n",
        "8. c) Both the input data and output labels.\n",
        "9. c) They extract and transform features.\n",
        "10. d) The Perceptron Convergence Theorem"
      ],
      "metadata": {
        "id": "_-BAridmVHIq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Ideas"
      ],
      "metadata": {
        "id": "NfxheA32uvSz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **Binary Disease Classification**:\n",
        "   - **Objective**: Predict whether a patient has a particular disease (e.g., diabetes) based on a set of clinical parameters.\n",
        "   - **Data**: Use patient data with attributes like age, blood pressure, blood sugar levels, and BMI.\n",
        "   \n",
        "2. **Medical Imaging**:\n",
        "   - **Objective**: Detect abnormalities such as tumors in medical images.\n",
        "   - **Data**: Preprocessed binary images where white represents the tumor and black represents normal tissue.\n",
        "   \n",
        "3. **Electronic Health Record (EHR) Analysis**:\n",
        "   - **Objective**: Predict patient readmissions based on their EHR.\n",
        "   - **Data**: Patient records with attributes such as prior admissions, diagnosis, medication, etc.\n",
        "\n",
        "4. **Genetic Data Analysis**:\n",
        "   - **Objective**: Classify patients based on susceptibility to a genetic disorder.\n",
        "   - **Data**: SNP (single nucleotide polymorphism) data or other genetic markers.\n",
        "   \n",
        "5. **Predicting Medication Response**:\n",
        "   - **Objective**: Determine if a patient will respond positively to a specific medication.\n",
        "   - **Data**: Patient records, including their medical history, current medications, and responses to those medications.\n",
        "   \n",
        "6. **Patient Triage**:\n",
        "   - **Objective**: Predict the urgency with which a patient should be seen in an emergency room setting.\n",
        "   - **Data**: Patient symptoms, vitals, and chief complaints upon ER entry.\n",
        "   \n",
        "7. **Optimizing Therapy Sessions**:\n",
        "   - **Objective**: Predict the optimal duration for physical therapy sessions for post-surgery patients.\n",
        "   - **Data**: Patient data with attributes like age, type of surgery, pain levels, and initial mobility metrics.\n",
        "   \n",
        "8. **Mental Health Analysis**:\n",
        "   - **Objective**: Classify whether a person is likely to have depression based on questionnaire responses.\n",
        "   - **Data**: Responses from mental health questionnaires and diagnostic outcomes.\n",
        "   \n",
        "9. **Vaccine Efficacy**:\n",
        "   - **Objective**: Predict the efficacy of a vaccine for individuals based on their health metrics.\n",
        "   - **Data**: Patient age, weight, genetic markers, and previous vaccine responses.\n",
        "   \n",
        "10. **Sleep Pattern Analysis**:\n",
        "   - **Objective**: Classify sleep quality (good or bad) based on metrics from a sleep monitor.\n",
        "   - **Data**: Sleep duration, number of awakenings, REM cycle data, etc.\n",
        "   \n",
        "11. **Predicting Surgical Outcomes**:\n",
        "   - **Objective**: Predict the success of a surgical procedure based on patient data.\n",
        "   - **Data**: Patient health metrics before surgery, type of surgery, and surgeon's experience.\n",
        "   \n",
        "12. **Drug Side-effects Prediction**:\n",
        "   - **Objective**: Predict potential side effects in patients when given a new drug.\n",
        "   - **Data**: Patient medical history, current medications, and reported side effects from trials.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "p4C2bpTAu0St"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practical Example"
      ],
      "metadata": {
        "id": "0QBw-Da2Kout"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's a working example of the Perceptron model using a real-world healthcare example dataset. In this example, we'll use the famous \"Breast Cancer Wisconsin\" dataset, which contains features computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. The task is to classify the tumors as either malignant (cancerous) or benign (non-cancerous)."
      ],
      "metadata": {
        "id": "h4DYMke0Km_w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the breast cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data\n",
        "y = data.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, learning_rate=0.01, n_epochs=100):\n",
        "        self.learning_rate = learning_rate\n",
        "        self.n_epochs = n_epochs\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.weights = np.zeros(X.shape[1])\n",
        "        self.bias = 0\n",
        "\n",
        "        for _ in range(self.n_epochs):\n",
        "            for xi, yi in zip(X, y):\n",
        "                prediction = self.predict(xi)\n",
        "                update = self.learning_rate * (yi - prediction)\n",
        "                self.weights += update * xi\n",
        "                self.bias += update\n",
        "\n",
        "    def predict(self, X):\n",
        "        linear_output = np.dot(X, self.weights) + self.bias\n",
        "        return np.where(linear_output >= 0, 1, 0)\n",
        "\n",
        "# Create and train the Perceptron model\n",
        "perceptron = Perceptron(learning_rate=0.01, n_epochs=1000)\n",
        "perceptron.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = perceptron.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "dQBu4B6xKZmG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In this example, we define a `Perceptron` class with methods for training and prediction. We load the breast cancer dataset, split it into training and testing sets, and standardize the features. Then, we create an instance of the `Perceptron` class, fit it to the training data, make predictions on the test data, and calculate the accuracy of the model.\n",
        "\n",
        "Keep in mind that the Perceptron is a simple model and might not perform as well as more advanced algorithms like Support Vector Machines (SVMs) or neural networks for complex datasets like healthcare data. This example serves as a basic illustration of how the Perceptron works."
      ],
      "metadata": {
        "id": "6tqshag0Kvhw"
      }
    }
  ]
}