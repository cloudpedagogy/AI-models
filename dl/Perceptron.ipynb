{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNoqGkFWSrJNWM6R9pNmtTA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cloudpedagogy/models/blob/main/dl/Perceptron.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Perceptron Model Background"
      ],
      "metadata": {
        "id": "Kqoi-jiK_yhf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Perceptron is one of the earliest and simplest forms of neural networks, dating back to the late 1950s. It was proposed by Frank Rosenblatt and laid the foundation for modern neural network architectures. The Perceptron is a type of single-layer feedforward neural network, meaning it consists of only one layer of artificial neurons, also known as perceptrons.\n",
        "\n",
        "**Here's how the Perceptron works**:\n",
        "\n",
        "1. **Input Layer**: The Perceptron takes a set of input features, represented as a vector, where each feature is multiplied by a corresponding weight. These weighted inputs are then summed up.\n",
        "\n",
        "2. **Activation Function**: The summed value is then passed through an activation function. Traditionally, a step function was used, but nowadays, other activation functions like the sigmoid or ReLU are more common.\n",
        "\n",
        "3. **Output**: The output of the activation function determines the final output of the Perceptron, usually binary (0 or 1) in the case of a single Perceptron.\n",
        "\n",
        "4. **Learning**: The Perceptron learns by adjusting its weights based on the error generated by comparing its output to the desired output. The process is called the Perceptron learning rule and is based on the concept of supervised learning.\n",
        "\n",
        "**Pros of Perceptron**:\n",
        "1. Simplicity: Perceptrons are straightforward and easy to understand, making them a good starting point for learning about neural networks.\n",
        "2. Fast Training: Due to their simplicity, training a Perceptron is relatively fast compared to more complex neural networks.\n",
        "3. Good for Linear Separability: Perceptrons work well for problems that are linearly separable, where a single straight line can classify the data.\n",
        "\n",
        "**Cons of Perceptron**:\n",
        "1. Limited Representational Power: The Perceptron can only learn linear decision boundaries, making it unsuitable for problems that require non-linear separation.\n",
        "2. Not Suitable for Complex Tasks: Perceptrons are not capable of handling tasks with high complexity or those that require learning intricate patterns.\n",
        "3. Convergence Issues: The Perceptron learning rule has convergence guarantees only for linearly separable data. In cases where the data is not linearly separable, the learning process might not converge to a solution.\n",
        "\n",
        "**When to use Perceptron**:\n",
        "The Perceptron is mostly used for educational purposes and simple problems where the data is linearly separable. If you have a binary classification problem with easily separable data, a single-layer Perceptron might be sufficient. However, in most real-world scenarios, where data is rarely linearly separable, you'll need more complex neural network architectures like multi-layer perceptrons (MLPs), convolutional neural networks (CNNs), or recurrent neural networks (RNNs) to achieve better performance. These advanced architectures can handle non-linear patterns and complex tasks effectively."
      ],
      "metadata": {
        "id": "Hf6fGgo-66M5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code Example"
      ],
      "metadata": {
        "id": "u-WdsUIKbWOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "class Perceptron:\n",
        "    def __init__(self, input_size, learning_rate=0.1, epochs=100):\n",
        "        self.weights = np.random.rand(input_size)\n",
        "        self.bias = np.random.rand()\n",
        "        self.learning_rate = learning_rate\n",
        "        self.epochs = epochs\n",
        "\n",
        "    def predict(self, inputs):\n",
        "        summation = np.dot(inputs, self.weights) + self.bias\n",
        "        return 1 if summation >= 0 else 0\n",
        "\n",
        "    def train(self, training_data, labels):\n",
        "        for epoch in range(self.epochs):\n",
        "            for inputs, label in zip(training_data, labels):\n",
        "                prediction = self.predict(inputs)\n",
        "                self.weights += self.learning_rate * (label - prediction) * inputs\n",
        "                self.bias += self.learning_rate * (label - prediction)\n",
        "\n",
        "# Example usage with logical OR function\n",
        "data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "labels = np.array([0, 1, 1, 1])\n",
        "\n",
        "# Create and train the Perceptron model\n",
        "input_size = 2\n",
        "perceptron_model = Perceptron(input_size)\n",
        "perceptron_model.train(data, labels)\n",
        "\n",
        "# Test the trained model\n",
        "test_data = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "for inputs in test_data:\n",
        "    prediction = perceptron_model.predict(inputs)\n",
        "    print(f\"Input: {inputs}, Prediction: {prediction}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "mCxhx4ScEnG8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code breakdown"
      ],
      "metadata": {
        "id": "ExxOxfDl1VGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Import libraries: The code starts by importing the required library `numpy` which is used for numerical computations.\n",
        "\n",
        "2. Define the `Perceptron` class: The code defines a class called `Perceptron`, which is a simple implementation of a single-layer perceptron. A perceptron is a basic building block of neural networks.\n",
        "\n",
        "3. Initialize the perceptron: In the `__init__` method of the `Perceptron` class, the perceptron is initialized with random weights and bias. The `input_size` parameter specifies the number of input features, `learning_rate` sets the step size for weight and bias updates during training, and `epochs` sets the number of training iterations.\n",
        "\n",
        "4. Predict method: The `predict` method takes an input array (`inputs`) and calculates the weighted sum of inputs multiplied by the weights (`np.dot(inputs, self.weights)`), adds the bias term, and returns 1 if the summation is greater than or equal to 0, otherwise returns 0. This is a binary prediction based on the sign of the summation.\n",
        "\n",
        "5. Train method: The `train` method is responsible for updating the weights and bias of the perceptron during training. It takes `training_data`, which is a 2D array containing input features, and `labels`, a 1D array with corresponding binary labels (0 or 1).\n",
        "\n",
        "6. Training loop: The `train` method contains a training loop with the number of epochs specified during initialization. It iterates over each epoch and then over each training example. For each example, it calculates the predicted output using the `predict` method, then updates the weights and bias based on the error (difference between the predicted output and the actual label) and the learning rate.\n",
        "\n",
        "7. Example usage with the logical OR function: The code demonstrates the usage of the `Perceptron` class to learn the logical OR function. It defines the logical OR data (`data`) and labels (`labels`) as NumPy arrays.\n",
        "\n",
        "8. Create and train the Perceptron model: It creates a `Perceptron` model with `input_size = 2` (as there are two input features) and trains the model using the `train` method on the provided data and labels.\n",
        "\n",
        "9. Test the trained model: The code tests the trained perceptron by providing test data (`test_data`) and iterating through each input. For each input, it makes a prediction using the `predict` method and prints the input along with the predicted value (0 or 1).\n",
        "\n",
        "This example is a basic implementation of a perceptron for a simple logical OR function, but it showcases the core principles of a single-layer neural network. In practice, perceptrons are used as building blocks for more complex neural network architectures to solve more challenging tasks."
      ],
      "metadata": {
        "id": "KPsAD_PJExFA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Real world application"
      ],
      "metadata": {
        "id": "WhhFu5HS2c7d"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's consider a real-world example of using the Perceptron model in a healthcare setting for diagnosing a medical condition based on patient data.\n",
        "\n",
        "**Example: Diagnosing Diabetes using Perceptron**\n",
        "\n",
        "Problem: We want to develop a simple binary classifier using the Perceptron model to predict whether a patient has diabetes or not based on certain medical features.\n",
        "\n",
        "Dataset: We have a dataset containing medical records of patients, where each data point represents a patient and includes the following features:\n",
        "1. Age: The age of the patient.\n",
        "2. BMI: Body Mass Index, a measure of body fat based on weight and height.\n",
        "3. Blood Pressure: The patient's blood pressure.\n",
        "4. Glucose Level: The patient's fasting blood glucose level.\n",
        "5. Insulin Level: The patient's fasting insulin level.\n",
        "6. Diabetes Label: The binary label indicating whether the patient has diabetes (1) or not (0).\n",
        "\n",
        "Model: We'll use a single-layer Perceptron model for binary classification.\n",
        "\n",
        "**Steps:**\n",
        "\n",
        "1. **Data Collection**: Gather the patient data, including age, BMI, blood pressure, glucose level, insulin level, and whether they have diabetes or not (the ground truth label).\n",
        "\n",
        "2. **Data Preprocessing**: Normalize the features to have zero mean and unit variance, which helps the model converge faster. Split the dataset into training and testing sets.\n",
        "\n",
        "3. **Perceptron Model**:\n",
        "   - Initialize the weights and bias with random values.\n",
        "   - Define the activation function (e.g., step function or sigmoid function) to transform the model's output into binary predictions.\n",
        "   - Define the learning rate, which controls how much the weights are updated during each iteration.\n",
        "\n",
        "4. **Training**:\n",
        "   - Iterate through the training set and update the model's weights and bias based on the prediction error.\n",
        "   - The prediction error is calculated as the difference between the predicted label and the true label.\n",
        "   - Adjust the weights and bias using the learning rate and the prediction error.\n",
        "   - Continue training for multiple epochs (passes through the entire training set) to improve the model's performance.\n",
        "\n",
        "5. **Evaluation**:\n",
        "   - After training, use the trained Perceptron model to make predictions on the testing set.\n",
        "   - Compare the model's predictions with the ground truth labels to calculate accuracy, precision, recall, F1 score, etc., to evaluate the model's performance.\n",
        "\n",
        "6. **Inference**:\n",
        "   - Once the model is trained and evaluated, it can be deployed to predict diabetes in new patients.\n",
        "   - Given the medical features of a new patient, pass the data through the trained Perceptron to obtain the predicted label (0 for no diabetes, 1 for diabetes).\n",
        "\n",
        "This real-world example shows how the Perceptron model can be applied in a healthcare setting for diagnosing diabetes based on patient data. Keep in mind that this is a simple example, and in practice, more sophisticated models and extensive data preprocessing would be used to achieve better performance and accuracy in medical diagnosis. Additionally, medical diagnosis involves complex decision-making, and machine learning models should be used with caution, always in conjunction with expert medical knowledge and oversight."
      ],
      "metadata": {
        "id": "aHXgwZKNFk8f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FAQ"
      ],
      "metadata": {
        "id": "-Ru32IH24En-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. What is a Perceptron?\n",
        "   A Perceptron is the simplest form of an artificial neural network, inspired by the biological neurons in the human brain. It consists of a single layer of interconnected nodes (neurons) that can make simple binary decisions.\n",
        "\n",
        "2. Who invented the Perceptron?\n",
        "   The Perceptron was invented by Frank Rosenblatt in 1957 at the Cornell Aeronautical Laboratory, now known as the Cornell University School of Operations Research and Information Engineering.\n",
        "\n",
        "3. How does a Perceptron work?\n",
        "   A Perceptron takes multiple inputs, each with an associated weight. It sums up the weighted inputs and applies an activation function to produce the output. The output is usually binary (0 or 1) based on whether the sum exceeds a certain threshold.\n",
        "\n",
        "4. What is the \"Perceptron Convergence Theorem\"?\n",
        "   The Perceptron Convergence Theorem, proved by Rosenblatt, states that a Perceptron can learn to classify linearly separable patterns correctly if the learning rate is small enough, and the data is linearly separable.\n",
        "\n",
        "5. What are the limitations of a Perceptron?\n",
        "   Perceptrons have some limitations, primarily being able to learn only linearly separable patterns. They cannot handle problems that require more complex decision boundaries or those with overlapping classes.\n",
        "\n",
        "6. How is a Multi-Layer Perceptron (MLP) different from a Perceptron?\n",
        "   Unlike a simple Perceptron, an MLP consists of multiple layers of interconnected nodes, including one or more hidden layers. This allows MLPs to handle more complex patterns and learn non-linear relationships.\n",
        "\n",
        "7. What are some applications of Perceptrons?\n",
        "   Perceptrons were historically used for pattern recognition and binary classification tasks. While they are not commonly used on their own today, their basic principles form the foundation of more advanced neural network architectures used in various applications like image recognition, natural language processing, and more.\n",
        "\n",
        "8. Can Perceptrons be used for regression tasks?\n",
        "   No, Perceptrons are primarily used for binary classification tasks. For regression tasks (predicting continuous values), other algorithms like linear regression or more advanced neural networks like MLPs with suitable activation functions are used.\n",
        "\n",
        "9. Are Perceptrons still relevant in modern machine learning?\n",
        "   While the original Perceptron model is not widely used in modern machine learning due to its limitations, the concept of simple neuron units and their role in forming more complex networks is still fundamental to modern deep learning models.\n",
        "\n",
        "10. How did the Perceptron influence the field of artificial intelligence?\n",
        "   The Perceptron was a significant early development in the field of artificial intelligence and neural networks. It played a crucial role in inspiring further research and paved the way for more advanced neural network architectures that emerged in later years."
      ],
      "metadata": {
        "id": "O41fWMkJT07w"
      }
    }
  ]
}