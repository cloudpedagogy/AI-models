{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNGIeeFmn4yQefsmlSEV4En",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cloudpedagogy/models/blob/main/dl/Multi_Layer_Perceptron_(MLP).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Background"
      ],
      "metadata": {
        "id": "rcSXRPR4_vKp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Multi-Layer Perceptron (MLP) is a type of feedforward artificial neural network, and it is one of the foundational architectures used in deep learning. It consists of multiple layers of interconnected nodes (neurons) organized in a sequence. Each node in a layer is connected to every node in the subsequent layer, and there are typically three types of layers: an input layer, one or more hidden layers, and an output layer.\n",
        "\n",
        "Here's a brief overview of the structure of an MLP:\n",
        "\n",
        "1. Input Layer: It receives the input data and passes it to the first hidden layer.\n",
        "\n",
        "2. Hidden Layers: These are intermediate layers between the input and output layers. Each hidden layer consists of multiple neurons, and they are responsible for learning and capturing complex patterns in the data through non-linear transformations.\n",
        "\n",
        "3. Output Layer: The final layer that produces the output of the model. The number of neurons in the output layer depends on the type of problem you're trying to solve (e.g., regression, classification).\n",
        "\n",
        "Pros of Multi-Layer Perceptron (MLP):\n",
        "\n",
        "1. Flexibility: MLP can be used for a wide range of tasks, including regression, classification, and even approximation of complex functions.\n",
        "\n",
        "2. Non-Linearity: With multiple hidden layers and activation functions, MLP can learn non-linear relationships in the data, allowing it to model more complex patterns.\n",
        "\n",
        "3. Universal Approximator: Under certain conditions, MLP has been proven to be a universal function approximator, meaning it can approximate any continuous function to any desired degree of accuracy given enough neurons and training.\n",
        "\n",
        "4. Availability of Libraries: There are many libraries and frameworks that support building MLPs easily, such as TensorFlow and PyTorch.\n",
        "\n",
        "Cons of Multi-Layer Perceptron (MLP):\n",
        "\n",
        "1. Overfitting: MLPs are prone to overfitting, especially when the model is large or the data is limited. Regularization techniques are often required to mitigate this issue.\n",
        "\n",
        "2. Training Complexity: Training an MLP can be computationally expensive and time-consuming, particularly for large datasets and complex architectures.\n",
        "\n",
        "3. Hyperparameter Sensitivity: MLPs have several hyperparameters that need to be tuned properly, and their performance can be sensitive to these hyperparameters.\n",
        "\n",
        "4. Lack of Spatial Information: MLPs do not consider the spatial relationships present in input data, making them less suitable for tasks like image and natural language processing compared to specialized architectures like Convolutional Neural Networks (CNNs) and Recurrent Neural Networks (RNNs).\n",
        "\n",
        "When to use Multi-Layer Perceptron (MLP):\n",
        "\n",
        "1. Tabular Data: MLPs can be effective for tabular data with numerical features, especially when there are non-linear relationships between the features and the target variable.\n",
        "\n",
        "2. Simple Tasks: MLPs can be a good choice for simple classification or regression tasks when the dataset is not too large, and you don't have access to specialized architectures like CNNs or RNNs.\n",
        "\n",
        "3. Benchmarks and Comparisons: MLPs can serve as a baseline model for various tasks, allowing you to compare the performance of other, more complex models against it.\n",
        "\n",
        "4. Learning: Building an MLP is a good starting point to understand the basics of neural networks and their training process before moving on to more advanced architectures.\n",
        "\n",
        "However, for more complex tasks like image recognition or natural language processing, you might want to explore CNNs or RNNs, respectively, as they are better suited for handling spatial information and sequential data."
      ],
      "metadata": {
        "id": "dlr6szOT7E2l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code Example"
      ],
      "metadata": {
        "id": "kV0YdNq_FV9r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.datasets import load_iris\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Load the Iris dataset\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "# Convert target labels to one-hot encoding (required for multi-class classification)\n",
        "y_onehot = to_categorical(y)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_onehot, test_size=0.2, random_state=42)\n",
        "\n",
        "# Standardize the features (mean=0, standard deviation=1)\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Create the Multi-Layer Perceptron (MLP) model\n",
        "model = Sequential()\n",
        "\n",
        "# Add the input layer with 4 input features (for Iris dataset) and 8 neurons\n",
        "model.add(Dense(8, input_shape=(4,), activation='relu'))\n",
        "\n",
        "# Add one hidden layer with 5 neurons\n",
        "model.add(Dense(5, activation='relu'))\n",
        "\n",
        "# Add the output layer with 3 neurons (for 3 classes in the Iris dataset) and softmax activation\n",
        "model.add(Dense(3, activation='softmax'))\n",
        "\n",
        "# Compile the model with categorical cross-entropy loss (for multi-class classification)\n",
        "# and Adam optimizer\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "epochs = 100\n",
        "batch_size = 32\n",
        "model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "WdjpzBUzFRYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code breakdown"
      ],
      "metadata": {
        "id": "q2G-JPba1bMl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Import the required libraries:\n",
        "   - `numpy` (as `np`): For numerical operations on arrays.\n",
        "   - `pandas` (as `pd`): For data manipulation and analysis using DataFrames.\n",
        "   - `train_test_split`: For splitting the dataset into training and testing sets.\n",
        "   - `StandardScaler`: For standardizing the features.\n",
        "   - `load_iris`: For loading the Iris dataset.\n",
        "   - `Sequential`, `Dense`, and `to_categorical` from `tensorflow.keras`: For building and training the neural network model.\n",
        "\n",
        "2. Load the Iris dataset:\n",
        "   - The Iris dataset is a built-in dataset in scikit-learn, commonly used for classification tasks. It contains features (input data) and target labels (output data).\n",
        "   - `X`: Contains the feature data (input features) of shape (150, 4).\n",
        "   - `y`: Contains the target labels (0, 1, or 2) corresponding to the Iris species of shape (150,).\n",
        "\n",
        "3. Convert target labels to one-hot encoding:\n",
        "   - One-hot encoding is required for multi-class classification tasks. It converts the single integer labels into binary vectors, where each class is represented by a binary vector with 1 in the corresponding class index and 0s elsewhere.\n",
        "   - `to_categorical(y)`: Converts the integer target labels `y` to one-hot encoded binary vectors `y_onehot`.\n",
        "\n",
        "4. Split the data into training and testing sets:\n",
        "   - `train_test_split`: Splits the feature data (`X`) and one-hot encoded labels (`y_onehot`) into training and testing sets. The test set will be 20% of the whole dataset, and `random_state=42` ensures reproducibility of the random splitting.\n",
        "\n",
        "5. Standardize the features:\n",
        "   - `StandardScaler`: Scales the feature data to have zero mean and unit variance (standardization).\n",
        "   - `X_train = scaler.fit_transform(X_train)`: Applies the scaling on the training features.\n",
        "   - `X_test = scaler.transform(X_test)`: Applies the same scaling on the testing features using the parameters learned from the training data.\n",
        "\n",
        "6. Create the Multi-Layer Perceptron (MLP) model using the Keras Sequential API:\n",
        "   - A sequential model is a linear stack of layers.\n",
        "   - `model.add(Dense(8, input_shape=(4,), activation='relu'))`: Adds the input layer with 4 input features (for the Iris dataset) and 8 neurons with ReLU activation function.\n",
        "   - `model.add(Dense(5, activation='relu'))`: Adds one hidden layer with 5 neurons and ReLU activation function.\n",
        "   - `model.add(Dense(3, activation='softmax'))`: Adds the output layer with 3 neurons (for 3 classes in the Iris dataset) and a softmax activation function, which is suitable for multi-class classification.\n",
        "\n",
        "7. Compile the model:\n",
        "   - `model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])`: Compiles the model with categorical cross-entropy loss (for multi-class classification) and the Adam optimizer. The metric chosen is accuracy.\n",
        "\n",
        "8. Train the model:\n",
        "   - `epochs = 100`: Defines the number of training epochs (iterations over the entire dataset).\n",
        "   - `batch_size = 32`: Specifies the batch size for training.\n",
        "   - `model.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=1)`: Trains the model on the training data for the specified number of epochs.\n",
        "\n",
        "9. Evaluate the model on the test set:\n",
        "   - `loss, accuracy = model.evaluate(X_test, y_test)`: Evaluates the trained model on the test data and calculates the test loss and accuracy.\n",
        "   - `print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")`: Prints the test loss and accuracy.\n",
        "\n",
        "This code builds, trains, and evaluates a simple Multi-Layer Perceptron (MLP) model for multi-class classification of the Iris dataset. The goal is to predict the species of iris flowers based on four input features: sepal length, sepal width, petal length, and petal width."
      ],
      "metadata": {
        "id": "Ud08fTbiFb5o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Real world application"
      ],
      "metadata": {
        "id": "a8y_qj5S2i1C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A real-world example of using a Multi-Layer Perceptron (MLP) model in a healthcare setting is predicting the risk of developing a particular disease based on patient data. Let's consider the example of predicting the risk of heart disease based on various health-related features.\n",
        "\n",
        "**Healthcare Example: Heart Disease Risk Prediction**\n",
        "\n",
        "**Problem**: To predict whether a patient has a high or low risk of developing heart disease based on their health-related attributes.\n",
        "\n",
        "**Data**: The dataset contains patient records with various features, such as age, gender, blood pressure, cholesterol levels, presence of diabetes, smoking habits, and family history of heart disease. Each patient is labeled with a binary outcome indicating whether they have a high (1) or low (0) risk of developing heart disease.\n",
        "\n",
        "**MLP Model**: We will use an MLP model to perform the binary classification task of predicting heart disease risk. The MLP model consists of multiple layers of interconnected neurons, allowing it to learn complex patterns from the input data.\n",
        "\n",
        "**Implementation**:\n",
        "\n",
        "1. **Data Preprocessing**: The healthcare dataset is preprocessed to handle missing values, normalize numerical features, and encode categorical variables if necessary.\n",
        "\n",
        "2. **Feature Selection**: Based on domain knowledge and feature importance analysis, relevant features are selected for the prediction task.\n",
        "\n",
        "3. **Data Split**: The dataset is split into training and testing sets to evaluate the model's performance on unseen data.\n",
        "\n",
        "4. **Model Architecture**: The MLP model is defined with an input layer, one or more hidden layers, and an output layer. The number of neurons in the input layer depends on the number of features in the dataset, and the number of neurons in the output layer is set to 2 (representing high or low risk of heart disease).\n",
        "\n",
        "5. **Training**: The model is trained on the training data using an optimization algorithm (e.g., stochastic gradient descent) to minimize the loss function (e.g., binary cross-entropy).\n",
        "\n",
        "6. **Hyperparameter Tuning**: Parameters such as the number of hidden layers, the number of neurons in each layer, the learning rate, and the batch size are tuned to optimize the model's performance.\n",
        "\n",
        "7. **Model Evaluation**: The trained model is evaluated on the test set to assess its accuracy, precision, recall, and other relevant metrics for heart disease risk prediction.\n",
        "\n",
        "**Benefits**:\n",
        "- The MLP model can capture complex patterns and interactions among various patient attributes, leading to accurate predictions.\n",
        "- The model can assist healthcare professionals in identifying patients at high risk of heart disease, enabling timely intervention and personalized care plans.\n",
        "- ML models like MLP can be efficiently retrained as new data becomes available, adapting to changes in patient populations and improving performance over time.\n",
        "\n",
        "**Note**: In a real-world healthcare application, ensuring the privacy and security of patient data is crucial. Healthcare professionals and data scientists need to comply with relevant regulations and maintain strict data protection measures when working with sensitive medical information."
      ],
      "metadata": {
        "id": "pIZW725JFA5B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FAQ"
      ],
      "metadata": {
        "id": "AK5-JU5f4JQV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. What is an MLP, and how does it work?\n",
        "   - MLP is a type of artificial neural network that consists of multiple layers of interconnected neurons. It works by passing input data through these layers of neurons, where each neuron processes the input and applies an activation function to produce an output. The output of one layer becomes the input to the next layer, and this process continues until the final layer, which produces the model's output.\n",
        "\n",
        "2. How does the training process of an MLP work?\n",
        "   - The training process of an MLP involves feeding the network with input data and comparing the predicted output with the actual target output. The difference between the predicted and target outputs is quantified using a loss function. The goal of training is to minimize this loss function by adjusting the weights and biases of the neurons using optimization algorithms like backpropagation.\n",
        "\n",
        "3. What are the activation functions used in MLPs?\n",
        "   - Activation functions introduce non-linearity to the network and are crucial for its learning capability. Common activation functions used in MLPs include the sigmoid function, hyperbolic tangent (tanh) function, and rectified linear unit (ReLU). More recently, variants like Leaky ReLU, Parametric ReLU, and Swish have gained popularity.\n",
        "\n",
        "4. Can MLPs handle complex data types like images or sequences?\n",
        "   - Yes, MLPs can handle complex data types like images or sequences, but they may not be the most efficient choice for such data due to their limitations in capturing spatial or sequential patterns. For tasks like image classification and natural language processing, specialized architectures like CNNs and RNNs, or their variants, are generally more effective.\n",
        "\n",
        "5. How is the architecture of an MLP determined?\n",
        "   - The architecture of an MLP, including the number of layers and the number of neurons in each layer, is typically determined through a process of experimentation and hyperparameter tuning. It depends on the complexity of the problem, the size of the dataset, and the available computational resources.\n",
        "\n",
        "6. What are the advantages of using an MLP?\n",
        "   - MLPs are versatile and can be applied to a wide range of tasks, including regression, classification, and function approximation. They can approximate complex non-linear functions given enough neurons and layers. Additionally, they are relatively simple to implement and understand compared to more specialized architectures.\n",
        "\n",
        "7. What are the main challenges of using an MLP?\n",
        "   - MLPs are prone to overfitting, especially when dealing with small datasets or complex architectures. Training an MLP can be computationally expensive and time-consuming, especially with a large number of layers and neurons. Also, selecting the right hyperparameters can be challenging and may require significant experimentation.\n",
        "\n",
        "8. Can MLPs be used in deep learning?\n",
        "   - MLPs with multiple hidden layers are often referred to as deep neural networks (DNNs). While MLPs are part of the deep learning family, more advanced architectures like CNNs and RNNs have become more popular in modern deep learning due to their ability to handle spatial and sequential data more effectively.\n",
        "\n",
        "9. Are there any alternatives to MLPs for simple tasks?\n",
        "   - Yes, for simple tasks, single-layer perceptrons or logistic regression models can be used as alternatives to MLPs. These models have fewer parameters and may be more suitable when the data is linearly separable.\n",
        "\n",
        "10. What are some real-world applications of MLPs?\n",
        "    - MLPs have been successfully used in various applications, including image recognition, speech recognition, natural language processing, fraud detection, and financial forecasting. They have also found applications in medical diagnosis, recommendation systems, and control systems, among others."
      ],
      "metadata": {
        "id": "q5j5GrDs6Yw2"
      }
    }
  ]
}