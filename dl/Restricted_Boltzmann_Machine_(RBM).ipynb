{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyO4M1wBzG0L9Yeta/zmX+wO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cloudpedagogy/models/blob/main/dl/Restricted_Boltzmann_Machine_(RBM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Background"
      ],
      "metadata": {
        "id": "bj9DGOXiBLOT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Restricted Boltzmann Machine (RBM) is a type of generative stochastic artificial neural network. It falls under the broader category of unsupervised learning algorithms and is particularly useful in areas such as collaborative filtering, feature learning, dimensionality reduction, and generative modeling.\n",
        "\n",
        "Here's an overview of RBM, along with its pros and cons, and when you should consider using it:\n",
        "\n",
        "**Restricted Boltzmann Machine (RBM):**\n",
        "- RBMs are probabilistic graphical models that consist of visible units and hidden units, where each unit can be binary or real-valued.\n",
        "- It's called \"restricted\" because there are no connections between units within the same layer (no visible-to-visible or hidden-to-hidden connections).\n",
        "- During training, RBMs learn to model the probability distribution of the training data by adjusting their weights to minimize the difference between the training data and the model's generated samples.\n",
        "\n",
        "**Pros of RBM:**\n",
        "1. **Generative Modeling:** RBMs can be used to generate new samples similar to the training data. This makes them useful for tasks like data augmentation and creating synthetic data for training other models.\n",
        "2. **Unsupervised Learning:** RBMs can learn patterns in unlabeled data, making them suitable for unsupervised learning tasks like pretraining deep neural networks or learning meaningful representations from data.\n",
        "3. **Dimensionality Reduction:** RBMs can learn compressed representations of data by using a smaller number of hidden units compared to the input features.\n",
        "4. **Collaborative Filtering:** RBMs have been successfully used in recommendation systems to model user-item interactions and predict missing values.\n",
        "5. **Training Efficiency:** RBMs can be trained using efficient algorithms such as Contrastive Divergence (CD), which helps speed up the learning process.\n",
        "\n",
        "**Cons of RBM:**\n",
        "1. **Limited Representational Power:** RBMs may struggle with capturing complex dependencies and hierarchies in data, which can be better handled by more advanced deep learning architectures like Deep Belief Networks (DBNs) or deep neural networks.\n",
        "2. **Training Challenges:** While CD makes training more efficient, it can still be computationally expensive, especially for large datasets.\n",
        "3. **Hyperparameter Tuning:** RBMs have several hyperparameters that need to be carefully tuned for optimal performance, which can be time-consuming.\n",
        "4. **Reconstruction Error:** The quality of generated samples might not be as high as other more advanced generative models like Variational Autoencoders (VAEs) or Generative Adversarial Networks (GANs).\n",
        "\n",
        "**When to Use RBM:**\n",
        "Consider using RBMs in the following scenarios:\n",
        "1. **Unlabeled Data:** When you have a large amount of unlabeled data and you want to learn useful representations from it.\n",
        "2. **Pretraining Deep Networks:** RBMs can be used as a pretraining step for deep neural networks to initialize the weights before fine-tuning with supervised learning.\n",
        "3. **Collaborative Filtering:** For building recommendation systems or collaborative filtering tasks where you want to predict user preferences based on past interactions.\n",
        "4. **Generative Modeling:** If you need to generate synthetic data that resembles the original data distribution, RBMs can be useful for generative modeling tasks.\n",
        "\n"
      ],
      "metadata": {
        "id": "dRu2hTMF9ifg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code Example"
      ],
      "metadata": {
        "id": "k4dWBDdAbK_S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_openml\n",
        "from sklearn.neural_network import BernoulliRBM\n",
        "\n",
        "# Load the MNIST dataset\n",
        "mnist = fetch_openml('mnist_784', version=1)\n",
        "data = mnist.data / 255.0  # Scale the data between 0 and 1\n",
        "\n",
        "# Create and train the Restricted Boltzmann Machine\n",
        "rbm = BernoulliRBM(n_components=100, learning_rate=0.01, n_iter=10, random_state=0)\n",
        "rbm.fit(data)\n",
        "\n",
        "# Helper function to visualize the weights learned by the RBM\n",
        "def plot_weights(rbm, n_cols=10):\n",
        "    n_hidden_units = rbm.n_components\n",
        "    n_rows = int(np.ceil(n_hidden_units / n_cols))\n",
        "\n",
        "    plt.figure(figsize=(n_cols, n_rows))\n",
        "    for i in range(n_hidden_units):\n",
        "        plt.subplot(n_rows, n_cols, i + 1)\n",
        "        plt.imshow(rbm.components_[i].reshape(28, 28), cmap='gray', interpolation='nearest')\n",
        "        plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Visualize the learned features (weights) by the RBM\n",
        "plot_weights(rbm)\n"
      ],
      "metadata": {
        "id": "MdriKp_WUrht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code breakdown"
      ],
      "metadata": {
        "id": "NEYZ3KHk02YY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Import the required libraries:\n",
        "   - `numpy` (imported as `np`): A library for numerical computing in Python.\n",
        "   - `matplotlib.pyplot` (imported as `plt`): A plotting library used for visualizations.\n",
        "   - `sklearn.datasets`: A module from scikit-learn that provides various datasets for machine learning tasks.\n",
        "   - `sklearn.neural_network.BernoulliRBM`: A class for training Restricted Boltzmann Machines (RBMs).\n",
        "\n",
        "2. Load the MNIST dataset:\n",
        "   - `fetch_openml('mnist_784', version=1)`: Fetches the MNIST dataset, which consists of grayscale images of handwritten digits from 0 to 9, each of size 28x28 pixels.\n",
        "   - The dataset contains the 'data' and 'target' attributes. Here, we normalize the pixel values to scale them between 0 and 1 by dividing by 255.0.\n",
        "\n",
        "3. Create and train the Restricted Boltzmann Machine (RBM):\n",
        "   - `BernoulliRBM(n_components=100, learning_rate=0.01, n_iter=10, random_state=0)`: Initializes a BernoulliRBM object with 100 hidden units (components), a learning rate of 0.01, and 10 training iterations. The `random_state` parameter is set for reproducibility.\n",
        "   - `rbm.fit(data)`: Trains the RBM using the data loaded from MNIST. The RBM tries to learn a compact representation of the input data by finding lower-dimensional features that capture patterns in the data.\n",
        "\n",
        "4. Define a helper function to visualize the weights learned by the RBM:\n",
        "   - `def plot_weights(rbm, n_cols=10)`: Defines a function called `plot_weights` that takes the trained RBM and an optional parameter `n_cols` (default value is 10).\n",
        "   - The function visualizes the learned weights (features) of the RBM. The number of columns (`n_cols`) is used to organize the visualizations.\n",
        "\n",
        "5. Visualize the learned features (weights) by the RBM:\n",
        "   - `plot_weights(rbm)`: Calls the `plot_weights` function with the trained RBM as an argument to visualize the learned features.\n",
        "   - The function displays a grid of images, where each image corresponds to a learned feature (hidden unit) in the RBM. The RBM tries to capture high-level patterns in the data as these learned features.\n",
        "\n",
        "The code shows how to use an RBM to learn features from the MNIST dataset and visualize the learned features as a grid of images. RBMs are unsupervised learning models that can be used for feature learning and pretraining deep neural networks. The learned features in this example represent lower-dimensional representations of the input data, capturing patterns that are useful for reconstructing the original data or for further downstream tasks such as classification or clustering."
      ],
      "metadata": {
        "id": "FD4oe8dc1UHR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Real world application"
      ],
      "metadata": {
        "id": "_oG4v5lD2Lgy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A real-world example of using Restricted Boltzmann Machines (RBM) in a healthcare setting is in the field of medical imaging analysis. RBMs can be employed for feature learning and extraction from medical images, which is a crucial step in various medical image processing tasks.\n",
        "\n",
        "Let's consider the application of RBMs in detecting abnormalities in X-ray images:\n",
        "\n",
        "**Example: Detection of Pneumonia in Chest X-rays using RBM**\n",
        "\n",
        "**1. Data Collection:** A large dataset of chest X-ray images is collected, containing both normal and pneumonia-affected images.\n",
        "\n",
        "**2. Preprocessing:** The images are preprocessed to remove noise, resize them to a consistent resolution, and ensure uniformity in the dataset.\n",
        "\n",
        "**3. RBM Feature Learning:** RBMs are used for unsupervised feature learning. The RBM is trained on a subset of the X-ray images without any labels. The RBM aims to learn representative features from the images, capturing patterns that differentiate normal and pneumonia-affected lungs.\n",
        "\n",
        "**4. Feature Extraction:** Once the RBM is trained, it is used to extract features from the entire dataset of chest X-rays, both normal and pneumonia cases.\n",
        "\n",
        "**5. Classification:** The extracted features are then fed into a classifier, such as a Support Vector Machine (SVM) or a neural network, along with their corresponding labels (normal or pneumonia).\n",
        "\n",
        "**6. Detection:** The classifier leverages the learned features to predict whether a given X-ray image shows signs of pneumonia or not.\n",
        "\n",
        "**7. Evaluation:** The performance of the system is evaluated using metrics like sensitivity, specificity, accuracy, and area under the receiver operating characteristic curve (AUC-ROC).\n",
        "\n",
        "**Benefits of using RBMs in this context:**\n",
        "- RBMs can learn complex and hierarchical features from raw image data, automatically identifying patterns that are relevant for pneumonia detection.\n",
        "- Unsupervised learning with RBMs allows the model to discover important features without requiring manual labeling, which can be expensive and time-consuming in the medical domain.\n",
        "- RBMs can handle a large amount of data, which is essential when dealing with extensive medical image datasets.\n",
        "\n",
        "By using RBMs for feature learning, the detection system can become more accurate and robust, assisting healthcare professionals in diagnosing pneumonia more efficiently and potentially aiding in early detection and treatment."
      ],
      "metadata": {
        "id": "56qSSVddHRQn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FAQ"
      ],
      "metadata": {
        "id": "YAsuEPkv3wuo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **What is a Restricted Boltzmann Machine (RBM)?**\n",
        "   - A Restricted Boltzmann Machine is a type of artificial neural network that belongs to the family of generative models. It consists of a visible layer and a hidden layer, but there are no connections within a layer (hence \"restricted\").\n",
        "\n",
        "2. **How does an RBM learn and generate data?**\n",
        "   - RBMs are trained using unsupervised learning. During training, they adjust their parameters to reconstruct the input data and maximize the likelihood of the training samples. After training, they can generate new data samples by sampling from the learned probability distribution.\n",
        "\n",
        "3. **What is the Boltzmann Machine's connection to statistical physics?**\n",
        "   - RBMs are inspired by statistical physics and the Boltzmann distribution, which is used to model the probabilities of states in a physical system. The energy-based formulation of RBMs is analogous to the concept of energy in statistical physics.\n",
        "\n",
        "4. **What are the applications of Restricted Boltzmann Machines?**\n",
        "   - RBMs have found applications in various domains, including collaborative filtering, dimensionality reduction, feature learning, topic modeling, and generative modeling of data such as images, music, and text.\n",
        "\n",
        "5. **Why are RBMs called generative models?**\n",
        "   - RBMs are generative models because they can learn the underlying probability distribution of the training data and then generate new samples from that distribution. This ability to create new data points makes them valuable in generating novel content.\n",
        "\n",
        "6. **What is the contrastive divergence algorithm used in RBM training?**\n",
        "   - The contrastive divergence (CD) algorithm is a popular method for training RBMs efficiently. It is an approximation of the log-likelihood gradient, which allows for faster convergence compared to traditional gradient-based methods.\n",
        "\n",
        "7. **Are RBMs still widely used in modern deep learning?**\n",
        "   - While RBMs have been historically significant in the development of deep learning, their usage has declined with the rise of more powerful and scalable models like deep neural networks and variants of autoencoders. However, they still hold relevance in certain scenarios and research areas.\n",
        "\n",
        "8. **Can RBMs be used in a deep learning architecture?**\n",
        "   - Yes, RBMs can be stacked to form Deep Belief Networks (DBNs). The hidden layers of one RBM become the visible layers of the next, allowing for deep architectures. However, this approach has mostly been replaced by more effective deep learning architectures like deep neural networks.\n",
        "\n",
        "9. **What are the limitations of RBMs?**\n",
        "   - RBMs suffer from slow convergence, especially when dealing with high-dimensional data. They are also sensitive to hyperparameters and require careful tuning. Additionally, training RBMs on large datasets can be computationally expensive.\n",
        "\n",
        "10. **Are there any extensions or variations of RBMs?**\n",
        "    - Yes, there are several variations of RBMs, such as the Gaussian-Bernoulli RBM, Binary-Binary RBM, and Factored RBM, each designed to address specific limitations or modeling requirements.\n",
        "\n",
        "Remember that as the field of deep learning and artificial intelligence progresses, new developments may emerge that could impact the popularity and use of certain models, including the RBM."
      ],
      "metadata": {
        "id": "i452MNjr7ypI"
      }
    }
  ]
}