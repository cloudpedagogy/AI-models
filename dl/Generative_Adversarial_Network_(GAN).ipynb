{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMvhUyooJQYIhqBkd7Roug/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cloudpedagogy/models/blob/main/dl/Generative_Adversarial_Network_(GAN).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Background"
      ],
      "metadata": {
        "id": "RD0DTIGM-Nf7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generative Adversarial Network (GAN) is a type of neural network architecture introduced by Ian Goodfellow and his colleagues in 2014. GANs are designed to generate realistic and high-quality synthetic data by learning from real data. The core idea behind GANs involves a competition between two neural networks: the generator and the discriminator.\n",
        "\n",
        "1. **How GANs work**:\n",
        "- Generator: The generator takes random noise as input and generates synthetic data (e.g., images, sounds, text) that mimics the distribution of the real data. Initially, the generator produces random and meaningless data.\n",
        "- Discriminator: The discriminator acts as a binary classifier, trying to distinguish between real data from the dataset and synthetic data generated by the generator.\n",
        "- Training process: The two networks play a minimax game. The generator aims to generate increasingly realistic data to fool the discriminator, while the discriminator tries to improve its ability to distinguish real data from fake data. As training progresses, the generator becomes more adept at generating convincing data, leading to increasingly realistic outputs.\n",
        "\n",
        "2. **Pros of GANs**:\n",
        "\n",
        "   - Realistic Data Generation: GANs excel at generating realistic and high-quality data that closely resembles the real data distribution, making them valuable in various creative applications, such as art, image synthesis, and content generation.\n",
        "\n",
        "   - No Explicit Rules: Unlike traditional rule-based methods, GANs learn patterns and features directly from the data, making them suitable for complex and diverse tasks where defining explicit rules is challenging.\n",
        "\n",
        "   - Data Augmentation: GANs can be used for data augmentation, creating additional training examples to improve the performance of other machine learning models with limited data.\n",
        "\n",
        "   - Versatility: GANs can be applied to various domains, including image synthesis, style transfer, super-resolution, text-to-image generation, video synthesis, and more.\n",
        "\n",
        "3. **Cons of GANs**:\n",
        "\n",
        "   - Training Instability: GANs are notoriously challenging to train, and achieving stable convergence can be difficult. Sometimes, the generator and discriminator may end up in a \"stalemate\" or collapse, leading to poor performance.\n",
        "\n",
        "   - Mode Collapse: In some cases, the generator may produce limited variations of data or get stuck generating only a subset of the target distribution, resulting in mode collapse.\n",
        "\n",
        "   - Evaluation Metrics: Quantitatively evaluating GAN performance is difficult, and traditional evaluation metrics like loss functions may not accurately capture the quality of generated samples.\n",
        "\n",
        "   - Computationally Demanding: GANs require significant computational resources, especially for large-scale models and high-resolution image synthesis.\n",
        "\n",
        "4. **When to use GANs**:\n",
        "\n",
        "   - Image Generation: GANs are commonly used for generating realistic images, such as in art generation, face synthesis, and style transfer.\n",
        "\n",
        "   - Data Augmentation: GANs can be employed to augment training data when data availability is limited, helping improve the performance of other machine learning models.\n",
        "\n",
        "   - Domain Translation: GANs can be used for tasks like converting images from one domain to another, like turning satellite images into maps or grayscale images to color.\n",
        "\n",
        "   - Anomaly Detection: GANs have been used for detecting anomalies in data by learning the normal data distribution and identifying deviations.\n",
        "\n",
        "   - Creative Applications: GANs have shown impressive results in various creative fields, like music and text generation, enabling new possibilities for artists and content creators.\n",
        "\n",
        "Remember that while GANs can produce amazing results, their training and optimization require expertise and computational resources. If you're new to GANs or have limited data, starting with pre-trained models or exploring simpler generative models like Variational Autoencoders (VAEs) might be a good idea."
      ],
      "metadata": {
        "id": "6RukLUKo86Le"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code Example"
      ],
      "metadata": {
        "id": "rLmFnLzNB2WJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "# Generator model\n",
        "def make_generator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(128, input_shape=(100,), use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Dense(256, use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Dense(512, use_bias=False))\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Dense(2, activation='tanh'))  # Output layer with two dimensions (x and y)\n",
        "    return model\n",
        "\n",
        "# Discriminator model\n",
        "def make_discriminator_model():\n",
        "    model = tf.keras.Sequential()\n",
        "    model.add(layers.Dense(512, input_shape=(2,)))\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Dense(256))\n",
        "    model.add(layers.LeakyReLU())\n",
        "\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))  # Output layer with one dimension (real or fake)\n",
        "    return model\n",
        "\n",
        "# GAN model\n",
        "def make_gan_model(generator, discriminator):\n",
        "    discriminator.trainable = False\n",
        "    model = tf.keras.Sequential([generator, discriminator])\n",
        "    return model\n",
        "\n",
        "# Random noise generator\n",
        "def generate_random_noise(batch_size, noise_dim):\n",
        "    return np.random.uniform(-1, 1, size=(batch_size, noise_dim))\n",
        "\n",
        "# Training parameters\n",
        "BATCH_SIZE = 64\n",
        "NOISE_DIM = 100\n",
        "EPOCHS = 2000\n",
        "\n",
        "# Create the models\n",
        "generator = make_generator_model()\n",
        "discriminator = make_discriminator_model()\n",
        "gan = make_gan_model(generator, discriminator)\n",
        "\n",
        "# Define loss and optimizers\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "gen_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "disc_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(EPOCHS):\n",
        "    # Generate random noise for the generator\n",
        "    noise = generate_random_noise(BATCH_SIZE, NOISE_DIM)\n",
        "\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "        # Generate fake samples from the noise using the generator\n",
        "        generated_samples = generator(noise, training=True)\n",
        "\n",
        "        # Get real samples from a 2D circle (you can replace this with your own data)\n",
        "        real_samples = np.random.normal(loc=0.5, scale=0.1, size=(BATCH_SIZE, 2))\n",
        "\n",
        "        # Discriminator loss for real and fake samples\n",
        "        real_output = discriminator(real_samples, training=True)\n",
        "        fake_output = discriminator(generated_samples, training=True)\n",
        "\n",
        "        gen_loss = cross_entropy(tf.ones_like(fake_output), fake_output)\n",
        "        disc_loss_real = cross_entropy(tf.ones_like(real_output), real_output)\n",
        "        disc_loss_fake = cross_entropy(tf.zeros_like(fake_output), fake_output)\n",
        "        disc_loss = disc_loss_real + disc_loss_fake\n",
        "\n",
        "    # Update generator and discriminator weights\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "\n",
        "    gen_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    disc_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))\n",
        "\n",
        "    # Plot the generated samples every 100 epochs\n",
        "    if epoch % 100 == 0:\n",
        "        plt.figure(figsize=(5, 5))\n",
        "        plt.scatter(real_samples[:, 0], real_samples[:, 1], c='b', label='Real')\n",
        "        plt.scatter(generated_samples[:, 0], generated_samples[:, 1], c='r', label='Generated')\n",
        "        plt.xlim(-1.5, 1.5)\n",
        "        plt.ylim(-1.5, 1.5)\n",
        "        plt.legend()\n",
        "        plt.title(f\"Epoch {epoch}\")\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "_SyLMb22SDnx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code breakdown"
      ],
      "metadata": {
        "id": "xe0zJ41SMnPi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "1. **Imports and Random Seed:**\n",
        "   - Import necessary libraries: `numpy` (as np), `matplotlib.pyplot` (as plt), and `tensorflow` (as tf).\n",
        "   - Set random seeds for reproducibility by using `tf.random.set_seed(42)` and `np.random.seed(42)`.\n",
        "\n",
        "2. **Generator Model:**\n",
        "   - `make_generator_model()`: Defines a generator model using a sequential architecture in TensorFlow. It consists of three dense layers with leaky ReLU activations and batch normalization, followed by an output layer with a tanh activation function (to output 2D data points). The generator takes random noise as input.\n",
        "\n",
        "3. **Discriminator Model:**\n",
        "   - `make_discriminator_model()`: Defines a discriminator model using a sequential architecture in TensorFlow. It consists of two dense layers with leaky ReLU activations, followed by an output layer with a sigmoid activation function (to classify real or fake samples). The discriminator takes 2D data points as input.\n",
        "\n",
        "4. **GAN Model:**\n",
        "   - `make_gan_model(generator, discriminator)`: Combines the generator and discriminator to form the GAN model. The discriminator is set to non-trainable during GAN training.\n",
        "\n",
        "5. **Random Noise Generator:**\n",
        "   - `generate_random_noise(batch_size, noise_dim)`: Generates random noise as input for the generator. It returns an array of random values between -1 and 1 with the specified batch size and noise dimension.\n",
        "\n",
        "6. **Training Parameters:**\n",
        "   - `BATCH_SIZE`: The batch size used during training.\n",
        "   - `NOISE_DIM`: The dimension of the random noise vector used as input for the generator.\n",
        "   - `EPOCHS`: The number of training epochs.\n",
        "\n",
        "7. **Create Models:**\n",
        "   - Create instances of the generator, discriminator, and GAN models using the functions defined earlier.\n",
        "\n",
        "8. **Loss and Optimizers:**\n",
        "   - Define the loss function for the GAN as binary cross-entropy (`cross_entropy`).\n",
        "   - Create separate optimizers for the generator (`gen_optimizer`) and discriminator (`disc_optimizer`) using the Adam optimizer.\n",
        "\n",
        "9. **Training Loop:**\n",
        "   - For each epoch in the range of `EPOCHS`:\n",
        "     - Generate random noise for the generator.\n",
        "     - Use TensorFlow's `GradientTape` to compute gradients for both the generator and discriminator.\n",
        "     - Generate fake samples from the noise using the generator and real samples from a 2D circle using `np.random.normal`.\n",
        "     - Compute the discriminator loss for both real and fake samples, as well as the generator loss using the binary cross-entropy.\n",
        "     - Update the weights of the generator and discriminator using the computed gradients and their respective optimizers.\n",
        "\n",
        "10. **Plotting Generated Samples:**\n",
        "    - After every 100 epochs, the code plots the generated samples (in red) and the real samples (in blue) on a 2D scatter plot.\n",
        "\n",
        "Please note that the data used in this example is synthetic and randomly generated for demonstration purposes. In real-world scenarios, you would replace the `real_samples` with your actual data. Additionally, GAN training can be sensitive to hyperparameters and might require tuning for better results."
      ],
      "metadata": {
        "id": "_yYFo_SKSN-2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Real world application"
      ],
      "metadata": {
        "id": "6kYhiaK9ShZQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A real-world example of a Generative Adversarial Network (GAN) model in the healthcare setting is generating synthetic medical images for data augmentation and privacy preservation.\n",
        "\n",
        "**Example: Generating Synthetic Medical Images**\n",
        "\n",
        "**Objective:** The goal is to generate synthetic medical images that resemble real patient data to increase the diversity of the training dataset and preserve patient privacy.\n",
        "\n",
        "**Context:** In medical imaging, having a diverse and large dataset is crucial for training accurate and robust deep learning models. However, obtaining such datasets can be challenging due to privacy concerns and the limited availability of annotated medical images. Additionally, sharing sensitive patient data can be risky, as it might lead to patient re-identification.\n",
        "\n",
        "**Solution:** A GAN model can be used to address these challenges. The GAN consists of two neural networks, the generator, and the discriminator, that play a minimax game. The generator tries to produce synthetic medical images, and the discriminator tries to distinguish between real (from the original dataset) and fake (generated) images. Over time, the generator improves its ability to generate realistic images by fooling the discriminator, while the discriminator becomes better at distinguishing real from fake images.\n",
        "\n",
        "**Workflow:**\n",
        "1. **Data Preprocessing:** Prepare a dataset of real medical images with appropriate labels, if available.\n",
        "\n",
        "2. **Creating the GAN:**\n",
        "   - **Generator Network:** The generator network takes random noise as input and generates synthetic medical images. It typically consists of convolutional layers, followed by upsampling layers to produce realistic images.\n",
        "   - **Discriminator Network:** The discriminator network is a binary classifier that takes medical images (real or synthetic) as input and predicts whether they are real or fake.\n",
        "   - **Training:** The generator and discriminator are trained alternately. The generator tries to generate realistic images to deceive the discriminator, while the discriminator learns to distinguish real from fake images. The training process is iterative, and both networks improve their performance over time.\n",
        "\n",
        "3. **Generating Synthetic Images:** Once the GAN is trained, the generator network can be used to generate synthetic medical images that resemble real patient data. These synthetic images can be used to augment the training dataset, increasing the diversity and size of the data available for training deep learning models.\n",
        "\n",
        "4. **Privacy Preservation:** The GAN-generated synthetic images do not contain actual patient data, ensuring privacy preservation. By using synthetic data, the risk of patient re-identification is minimized.\n",
        "\n",
        "**Benefits:**\n",
        "- The generated synthetic images help improve the performance of deep learning models, as they introduce greater diversity into the training dataset.\n",
        "- Patient privacy is preserved since the synthetic images are not real patient data.\n",
        "- The availability of more diverse data can lead to more robust and accurate medical image analysis models.\n",
        "\n",
        "**Note:** It's crucial to validate the performance of the trained models using real patient data and ensure that the synthetic images are of high quality and do not introduce biases that may affect downstream analysis. Additionally, the use of GANs in medical applications should comply with ethical guidelines and privacy regulations."
      ],
      "metadata": {
        "id": "S0T2hTDb97X3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FAQ"
      ],
      "metadata": {
        "id": "oNJpIQVnZVij"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. What is a Generative Adversarial Network (GAN)?\n",
        "   - A GAN is a type of deep learning model that consists of two neural networks, the generator, and the discriminator, which are trained simultaneously in a game-like setting. The generator generates synthetic data, while the discriminator tries to distinguish between real and fake data. They are pitted against each other, leading to the improvement of both networks over time.\n",
        "\n",
        "2. What is the purpose of GANs?\n",
        "   - GANs are used for generating new, realistic data that resembles a given training dataset. They have applications in image synthesis, video generation, audio generation, text-to-image synthesis, style transfer, and much more.\n",
        "\n",
        "3. How does a GAN work?\n",
        "   - The generator takes random noise as input and generates fake data samples. The discriminator, on the other hand, receives both real and fake data samples and tries to classify them as real or fake. During training, the generator aims to produce data that fools the discriminator, while the discriminator strives to correctly classify real and fake data.\n",
        "\n",
        "4. What are the challenges in training GANs?\n",
        "   - GANs are notoriously difficult to train and may suffer from issues like mode collapse, where the generator only produces a limited variety of outputs, or vanishing gradients, which can slow down training. Finding the right balance between generator and discriminator can be a challenge.\n",
        "\n",
        "5. What are some famous GAN architectures?\n",
        "   - DCGAN (Deep Convolutional GAN), CycleGAN, WGAN (Wasserstein GAN), StyleGAN, and BigGAN are some well-known GAN architectures that have made significant contributions to the field of generative modeling.\n",
        "\n",
        "6. How are GANs used in art and creativity?\n",
        "   - GANs have been utilized to create stunning artwork, generate music, compose poems, and even design new fashion styles. They offer exciting opportunities for creative expression and exploration.\n",
        "\n",
        "7. Can GANs be used for data augmentation?\n",
        "   - Yes, GANs can be used to augment training data by generating synthetic samples that can expand the diversity of the dataset, which can improve the performance of other machine learning models.\n",
        "\n",
        "8. What are the ethical implications of GANs?\n",
        "   - GANs have raised ethical concerns, particularly regarding the generation of realistic deepfakes, misinformation, or content that can be used maliciously. Ensuring responsible use and understanding potential biases is crucial when deploying GANs.\n",
        "\n",
        "9. How are GANs used in healthcare and medicine?\n",
        "   - GANs have been employed to generate synthetic medical images, aid in medical image segmentation, denoising, and data augmentation. They can also help in drug discovery and molecule design.\n",
        "\n",
        "10. What is the future of GANs?\n",
        "    - The future of GANs holds promising advancements in generating even more realistic and diverse data, addressing current training challenges, and applying them to an increasing number of real-world applications across various domains.\n",
        "\n",
        "Remember that the field of GANs is continually evolving, and new research and innovations may lead to further exciting developments in the future."
      ],
      "metadata": {
        "id": "gFr-99cOkitV"
      }
    }
  ]
}