{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMIW9U8Fxi7Yhfyb7wqyAQ2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cloudpedagogy/models/blob/main/ml/Logistic_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Background"
      ],
      "metadata": {
        "id": "dVON7gPT_JVG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic Regression is a statistical method used for binary classification problems, where the goal is to predict the probability that an instance belongs to a particular class. Despite its name, logistic regression is primarily a classification algorithm, not a regression algorithm. It works by modeling the relationship between the input features and the probability of the target variable being in one of two possible classes (e.g., yes/no, 0/1).\n",
        "\n",
        "The logistic regression model uses the logistic function (also known as the sigmoid function) to transform the output of a linear regression into the range [0, 1]. This output represents the probability of the instance belonging to one class, and the probability of it belonging to the other class is simply 1 minus the first probability.\n",
        "\n",
        "**Pros of Logistic Regression**:\n",
        "\n",
        "1. Simplicity: Logistic regression is relatively simple and easy to understand. It's a linear algorithm that can be implemented quickly.\n",
        "\n",
        "2. Interpretability: The model's coefficients can be interpreted to understand the influence of each feature on the predicted probability.\n",
        "\n",
        "3. Probabilistic Output: Logistic regression provides a probability score for the predicted class, which can be useful when you need to assess uncertainty.\n",
        "\n",
        "4. Works well with small datasets: Logistic regression can perform well even with limited data compared to more complex algorithms.\n",
        "\n",
        "5. Low computational cost: Training and making predictions with logistic regression are computationally efficient, making it suitable for large datasets.\n",
        "\n",
        "**Cons of Logistic Regression**:\n",
        "\n",
        "1. Limited to binary classification: Logistic regression is designed for binary classification problems and may not work well with multi-class classification tasks without modifications.\n",
        "\n",
        "2. Assumption of linearity: Logistic regression assumes a linear relationship between the features and the log-odds of the target variable, which might not hold true in all cases.\n",
        "\n",
        "3. Sensitive to outliers: Logistic regression can be sensitive to outliers, which might negatively impact its performance.\n",
        "\n",
        "4. May not handle complex relationships: For problems with highly nonlinear decision boundaries, logistic regression might not be the best choice.\n",
        "\n",
        "**When to use Logistic Regression**:\n",
        "\n",
        "Logistic Regression is a good choice under the following circumstances:\n",
        "\n",
        "1. Binary classification: When you have a binary classification problem, where you need to predict whether an instance belongs to one of two classes.\n",
        "\n",
        "2. Interpretable results: When you need to understand the contribution of individual features and their impact on the outcome.\n",
        "\n",
        "3. Linearly separable data: When the data is relatively well-separated by a linear decision boundary.\n",
        "\n",
        "4. Low computational resources: When computational resources are limited, as logistic regression is computationally efficient.\n",
        "\n",
        "However, if your problem involves multiple classes or has complex relationships between features and the target, you might consider other algorithms like Support Vector Machines (SVM), Random Forests, Gradient Boosting, or deep learning models like Neural Networks."
      ],
      "metadata": {
        "id": "M-ivCyzd7W3a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code Example"
      ],
      "metadata": {
        "id": "HkYHFaM1Ajkf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Load or create your dataset (replace this with your own data)\n",
        "# For example, if you have a CSV file named 'data.csv':\n",
        "# data = pd.read_csv('data.csv')\n",
        "# X = data.drop('target_column', axis=1)\n",
        "# y = data['target_column']\n",
        "\n",
        "# For demonstration purposes, let's create a synthetic dataset\n",
        "np.random.seed(42)\n",
        "num_samples = 1000\n",
        "num_features = 5\n",
        "X = np.random.randn(num_samples, num_features)\n",
        "coefficients = np.array([1.5, -2, 0.5, 0, 0])\n",
        "intercept = 1\n",
        "noise = 0.5 * np.random.randn(num_samples)\n",
        "y = (X.dot(coefficients) + intercept + noise) > 0\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and train the Logistic Regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "class_report = classification_report(y_test, y_pred)\n",
        "\n",
        "print(\"Accuracy:\", accuracy)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", class_report)\n"
      ],
      "metadata": {
        "id": "gXR-aXN5vuCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code breakdown"
      ],
      "metadata": {
        "id": "8HeUYS_mGlH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Import necessary libraries:\n",
        "   - `numpy`: Used for numerical operations and generating synthetic data.\n",
        "   - `pandas`: Used for data manipulation and handling the dataset (though in this case, we generate synthetic data).\n",
        "   - `train_test_split` from `sklearn.model_selection`: Used to split the data into training and testing sets.\n",
        "   - `LogisticRegression` from `sklearn.linear_model`: Used to create and train a logistic regression model.\n",
        "   - `accuracy_score`, `classification_report`, and `confusion_matrix` from `sklearn.metrics`: Used to evaluate the performance of the model.\n",
        "\n",
        "2. Create a synthetic dataset (for demonstration purposes):\n",
        "   - `np.random.seed(42)`: Sets the random seed for reproducibility.\n",
        "   - `num_samples`: Number of data samples to generate.\n",
        "   - `num_features`: Number of features in each sample.\n",
        "   - `X`: A randomly generated array of shape `(num_samples, num_features)` containing features.\n",
        "   - `coefficients`: An array of coefficients used to generate the target labels.\n",
        "   - `intercept`: An intercept term added to the target labels.\n",
        "   - `noise`: Random noise added to the target labels.\n",
        "   - `y`: Binary target labels generated based on the dot product of features and coefficients, with added noise. If the result is greater than 0, the label is True (1), otherwise False (0).\n",
        "\n",
        "3. Split the data into training and testing sets:\n",
        "   - `train_test_split(X, y, test_size=0.2, random_state=42)`: Splits the data (features `X` and target labels `y`) into training and testing sets. The test set size is 20% of the total data, and the random seed is set to 42 for reproducibility.\n",
        "\n",
        "4. Create and train the Logistic Regression model:\n",
        "   - `model = LogisticRegression()`: Creates an instance of the logistic regression model.\n",
        "   - `model.fit(X_train, y_train)`: Trains the logistic regression model on the training data (`X_train` and `y_train`).\n",
        "\n",
        "5. Make predictions on the test set:\n",
        "   - `y_pred = model.predict(X_test)`: Uses the trained model to predict the target labels for the test set (`X_test`).\n",
        "\n",
        "6. Evaluate the model:\n",
        "   - `accuracy = accuracy_score(y_test, y_pred)`: Computes the accuracy of the model's predictions compared to the true labels from the test set.\n",
        "   - `conf_matrix = confusion_matrix(y_test, y_pred)`: Generates a confusion matrix that provides information about the true positive, true negative, false positive, and false negative predictions.\n",
        "   - `class_report = classification_report(y_test, y_pred)`: Generates a classification report containing precision, recall, F1-score, and support for each class.\n",
        "\n",
        "7. Print the evaluation metrics:\n",
        "   - `print(\"Accuracy:\", accuracy)`: Prints the accuracy of the model's predictions on the test set.\n",
        "   - `print(\"Confusion Matrix:\\n\", conf_matrix)`: Prints the confusion matrix, showing the counts of true positive, true negative, false positive, and false negative predictions.\n",
        "   - `print(\"Classification Report:\\n\", class_report)`: Prints the classification report containing precision, recall, F1-score, and support for each class.\n",
        "\n",
        "The code demonstrates how to create a synthetic dataset, split it into training and testing sets, train a logistic regression model, make predictions, and evaluate the model's performance using accuracy, confusion matrix, and classification report."
      ],
      "metadata": {
        "id": "oBVEx5zIvpG_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Real world application"
      ],
      "metadata": {
        "id": "OEwTOCUSR092"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's consider a real-world example of using logistic regression in a healthcare setting to predict the likelihood of a patient having a heart attack based on certain risk factors and medical history.\n",
        "\n",
        "**Problem Statement:**\n",
        "The healthcare facility wants to identify patients who are at a higher risk of experiencing a heart attack in the next year. They have collected data on various risk factors and medical history of a group of patients, along with information about whether they had a heart attack in the past year.\n",
        "\n",
        "**Dataset:**\n",
        "The dataset contains the following features for each patient:\n",
        "1. Age: Age of the patient (numeric).\n",
        "2. Gender: Gender of the patient (categorical: male or female).\n",
        "3. Blood Pressure: Systolic blood pressure of the patient (numeric).\n",
        "4. Cholesterol Level: Cholesterol level of the patient (numeric).\n",
        "5. Diabetes: Whether the patient has diabetes (binary: 1 for yes, 0 for no).\n",
        "6. Smoking: Whether the patient is a smoker (binary: 1 for yes, 0 for no).\n",
        "7. Family History: Whether there is a family history of heart disease (binary: 1 for yes, 0 for no).\n",
        "8. Heart Attack: Whether the patient had a heart attack in the past year (binary: 1 for yes, 0 for no).\n",
        "\n",
        "**Objective:**\n",
        "Build a logistic regression model that takes the patient's features as input and predicts the probability of the patient having a heart attack in the next year (Heart Attack = 1).\n",
        "\n",
        "**Steps:**\n",
        "1. Data Collection: Collect data on the features mentioned above from a sample of patients who visited the healthcare facility.\n",
        "\n",
        "2. Data Preprocessing: Preprocess the data by handling missing values, encoding categorical variables (e.g., one-hot encoding for gender), and splitting the data into training and testing sets.\n",
        "\n",
        "3. Model Training: Use the logistic regression algorithm to train the model on the training data. The model will learn the relationships between the input features and the likelihood of a heart attack.\n",
        "\n",
        "4. Model Evaluation: Evaluate the performance of the trained logistic regression model using metrics like accuracy, precision, recall, and F1-score on the test data. These metrics will provide insights into how well the model is predicting the occurrence of heart attacks.\n",
        "\n",
        "5. Interpretation: Examine the coefficients of the logistic regression model to understand the impact of each feature on the prediction. Positive coefficients indicate that an increase in the feature's value is associated with an increased risk of a heart attack, while negative coefficients indicate the opposite.\n",
        "\n",
        "6. Prediction: Once the logistic regression model is trained and evaluated, it can be used to predict the probability of a heart attack for new patients based on their features. The predicted probabilities can be used to prioritize patients for further screenings or interventions.\n",
        "\n",
        "7. Deployment: Integrate the trained logistic regression model into the healthcare facility's system so that it can be used in real-time to assess the risk of heart attacks for incoming patients.\n",
        "\n",
        "**Important Note:**\n",
        "While logistic regression can provide valuable insights and predictions, it is crucial to remember that healthcare decisions should not be solely based on the predictions of a single model. Predictive models should be used as tools to assist healthcare professionals in making informed decisions. It is essential to consider a holistic approach that combines medical expertise, patient history, and other diagnostic tests in making healthcare decisions."
      ],
      "metadata": {
        "id": "nh237JenD7Tt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FAQ"
      ],
      "metadata": {
        "id": "vQt1zqrMYkNA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. What is Logistic Regression, and how does it differ from Linear Regression?\n",
        "- Logistic Regression is a type of statistical model used for binary classification tasks. Unlike Linear Regression, which predicts continuous values, Logistic Regression predicts the probability of an input belonging to a particular class (usually 0 or 1). It uses the logistic function (sigmoid) to map the output to a probability range between 0 and 1.\n",
        "\n",
        "2. Why is it called \"Logistic\" Regression?\n",
        "- The name \"Logistic Regression\" comes from the logistic function used in the model. The logistic function is a sigmoid curve that maps any real-valued number to a value between 0 and 1, which makes it suitable for estimating probabilities in binary classification problems.\n",
        "\n",
        "3. Can Logistic Regression handle multi-class classification tasks?\n",
        "- While Logistic Regression is inherently designed for binary classification, it can be extended to handle multi-class problems using techniques like one-vs-all (also known as one-vs-rest) or softmax regression. One-vs-all involves training multiple binary classifiers for each class, while softmax regression generalizes the concept of logistic regression to multi-class scenarios.\n",
        "\n",
        "4. How does Logistic Regression make predictions based on probabilities?\n",
        "- After computing the probability of an input belonging to class 1 (p), Logistic Regression makes a decision based on a threshold value (usually 0.5). If p is greater than or equal to the threshold, the input is classified as class 1; otherwise, it is classified as class 0.\n",
        "\n",
        "5. Is the decision boundary always linear in Logistic Regression?\n",
        "- No, the decision boundary of Logistic Regression can be linear or non-linear, depending on the data and feature transformation. In simple cases, it may be linear, but when features are combined or transformed, the decision boundary can become non-linear.\n",
        "\n",
        "6. What are the advantages of Logistic Regression?\n",
        "- Logistic Regression is simple, interpretable, and computationally efficient. It works well with small to medium-sized datasets and can handle high-dimensional feature spaces.\n",
        "\n",
        "7. What are the limitations of Logistic Regression?\n",
        "- Logistic Regression may not perform well on complex datasets with non-linear relationships between features and target. It can also be sensitive to outliers and multicollinearity between features.\n",
        "\n",
        "8. Is feature scaling necessary for Logistic Regression?\n",
        "- Feature scaling is not always required for Logistic Regression. It depends on the optimization algorithm used. Gradient-based methods like gradient descent may benefit from feature scaling to improve convergence, but other algorithms like Newton-Raphson may not require it.\n",
        "\n",
        "9. Can Logistic Regression handle missing values in the dataset?\n",
        "- Missing values can be handled in Logistic Regression by either removing the samples with missing values or imputing them with appropriate values (e.g., mean, median, etc.) before training the model.\n",
        "\n",
        "10. What are some real-world applications of Logistic Regression?\n",
        "- Logistic Regression is widely used in various applications, including spam email detection, disease diagnosis, credit risk analysis, sentiment analysis, and predicting customer churn in businesses."
      ],
      "metadata": {
        "id": "4Le3TxIo5sUb"
      }
    }
  ]
}