{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNUKlmnEfUUpyzLeOUNlAyS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cloudpedagogy/AI-models/blob/main/ml/Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Linear Regression Model Background"
      ],
      "metadata": {
        "id": "SemPjC4r_Bcb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear Regression is a popular statistical method used for predicting numerical values based on the relationship between one or more independent variables (also called features or predictors) and a dependent variable (also known as the target or outcome). It assumes a linear relationship between the independent variables and the dependent variable. The goal of linear regression is to find the best-fitting line that minimizes the error between the predicted values and the actual values in the dataset.\n",
        "\n",
        "The equation of a simple linear regression with one independent variable can be represented as:\n",
        "\n",
        "$y = mx + b$\n",
        "\n",
        "Where:\n",
        "- $y$ is the dependent variable (target)\n",
        "- $x$ is the independent variable (feature)\n",
        "- $m$ is the slope of the line (representing the relationship between x and y)\n",
        "- $b$ is the y-intercept (representing the value of y when x is 0)\n",
        "\n",
        "For multiple linear regression (with more than one independent variable), the equation becomes:\n",
        "\n",
        "$y = b0 + b1*x1 + b2*x2 + ... + bn*xn$\n",
        "\n",
        "Where:\n",
        "- $b0$ is the y-intercept\n",
        "- $b1, b2, ..., bn$ are the coefficients for the independent variables $x1, x2, ..., xn$\n",
        "\n",
        "**Pros of Linear Regression**:\n",
        "1. Simplicity: Linear regression is straightforward and easy to understand, making it a good starting point for predictive modeling.\n",
        "2. Interpretability: The coefficients of the model provide insights into the relationship between the independent variables and the target variable.\n",
        "3. Fast computation: Training a linear regression model is computationally efficient, making it suitable for large datasets.\n",
        "4. Widely used: Linear regression is a fundamental technique that is widely applied in various fields, such as economics, finance, and social sciences.\n",
        "\n",
        "**Cons of Linear Regression**:\n",
        "1. Linearity assumption: Linear regression assumes a linear relationship between the independent variables and the target, which may not always be true in real-world scenarios.\n",
        "2. Sensitivity to outliers: Linear regression is sensitive to outliers in the data, and outliers can have a significant impact on the model's performance.\n",
        "3. Limited complexity: The model's simplicity can be a limitation when dealing with complex relationships in the data, where more advanced models might be required.\n",
        "4. Multicollinearity: If the independent variables are highly correlated, it can lead to multicollinearity issues, affecting the interpretability of the coefficients.\n",
        "\n",
        "**When to use Linear Regression**:\n",
        "Linear regression is appropriate when:\n",
        "1. You want to predict a numerical value (continuous target variable) based on one or more input features.\n",
        "2. There is a linear relationship between the input features and the target variable.\n",
        "3. You need a simple and interpretable model to gain insights into the relationships between variables.\n",
        "\n",
        "It is essential to evaluate your data and consider the assumptions of linear regression before applying it. If the relationship is nonlinear, you may need to consider using other regression models or machine learning algorithms. Also, make sure to preprocess your data, handle outliers, and check for multicollinearity before fitting the model."
      ],
      "metadata": {
        "id": "zqfCEnDAwiw9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code Example"
      ],
      "metadata": {
        "id": "eVK45xq4Ancr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "# Generate some sample data (replace this with your own dataset)\n",
        "np.random.seed(42)\n",
        "X = np.random.rand(100, 1) * 10\n",
        "y = 2 * X + 3 + np.random.randn(100, 1)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create and fit the Linear Regression model\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Print model performance metrics\n",
        "print(\"Mean Squared Error:\", mean_squared_error(y_test, y_pred))\n",
        "print(\"R-squared:\", r2_score(y_test, y_pred))\n",
        "\n",
        "# Visualize the model's predictions\n",
        "plt.scatter(X_test, y_test, color='blue', label='Actual')\n",
        "plt.plot(X_test, y_pred, color='red', linewidth=2, label='Predicted')\n",
        "plt.xlabel(\"X\")\n",
        "plt.ylabel(\"y\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "pT_ZoF4bvZ8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code breakdown"
      ],
      "metadata": {
        "id": "b94GmqURGpBS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. Import required libraries:\n",
        "   - `numpy` (as `np`): A library for numerical computing in Python.\n",
        "   - `pandas` (as `pd`): A library for data manipulation and analysis.\n",
        "   - `matplotlib.pyplot` (as `plt`): A library for data visualization.\n",
        "   - `sklearn.linear_model.LinearRegression`: A class representing the Linear Regression model from scikit-learn (a popular machine learning library).\n",
        "   - `sklearn.model_selection.train_test_split`: A function to split the data into training and testing sets.\n",
        "   - `sklearn.metrics.mean_squared_error`: A function to calculate the mean squared error, a common regression evaluation metric.\n",
        "   - `sklearn.metrics.r2_score`: A function to calculate the R-squared (coefficient of determination), another regression evaluation metric.\n",
        "\n",
        "2. Generate some sample data:\n",
        "   - `np.random.seed(42)`: Sets the random seed for reproducibility.\n",
        "   - `X`: A 1-dimensional NumPy array of shape (100, 1) containing random values between 0 and 10.\n",
        "   - `y`: A 1-dimensional NumPy array of shape (100, 1) representing the target variable `y`. It is created by applying the equation `y = 2 * X + 3 + random_noise`, where `random_noise` is drawn from a normal distribution (with mean 0 and standard deviation 1).\n",
        "\n",
        "3. Split the data into training and testing sets:\n",
        "   - `train_test_split(X, y, test_size=0.2, random_state=42)`: Splits the data into training and testing sets. 80% of the data is used for training, and 20% is used for testing. The `random_state` parameter ensures reproducibility of the split.\n",
        "\n",
        "4. Create and fit the Linear Regression model:\n",
        "   - `model = LinearRegression()`: Creates an instance of the LinearRegression class, representing a linear regression model.\n",
        "   - `model.fit(X_train, y_train)`: Fits the linear regression model to the training data (`X_train` and `y_train`).\n",
        "\n",
        "5. Make predictions on the test set:\n",
        "   - `y_pred = model.predict(X_test)`: Uses the trained model to make predictions on the test data (`X_test`) and stores the predicted values in `y_pred`.\n",
        "\n",
        "6. Print model performance metrics:\n",
        "   - `mean_squared_error(y_test, y_pred)`: Calculates the mean squared error between the actual test labels (`y_test`) and the predicted labels (`y_pred`).\n",
        "   - `r2_score(y_test, y_pred)`: Calculates the R-squared value, which represents the proportion of variance in the dependent variable (`y_test`) that is predictable from the independent variable (`y_pred`).\n",
        "\n",
        "7. Visualize the model's predictions:\n",
        "   - `plt.scatter(X_test, y_test, color='blue', label='Actual')`: Plots a scatter plot of the actual test data points (`X_test`, `y_test`) in blue.\n",
        "   - `plt.plot(X_test, y_pred, color='red', linewidth=2, label='Predicted')`: Plots a red line representing the model's predictions (`X_test`, `y_pred`) based on the fitted linear regression model.\n",
        "   - `plt.xlabel(\"X\")`: Adds a label to the x-axis of the plot.\n",
        "   - `plt.ylabel(\"y\")`: Adds a label to the y-axis of the plot.\n",
        "   - `plt.legend()`: Adds a legend to the plot.\n",
        "   - `plt.show()`: Displays the plot.\n",
        "\n",
        "This code demonstrates a simple linear regression example using scikit-learn. It generates sample data, splits it into training and testing sets, trains a linear regression model, makes predictions on the test set, evaluates the model's performance, and visualizes the actual and predicted data points."
      ],
      "metadata": {
        "id": "yi3UHl0Gvbj4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Real world application"
      ],
      "metadata": {
        "id": "0tND6eRtR9WU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's consider a real-world example of using linear regression in a healthcare setting to predict patient hospital readmission rates based on various medical and demographic features. The goal is to identify factors that may contribute to higher readmission rates, allowing healthcare providers to take proactive measures to reduce readmissions and improve patient outcomes.\n",
        "\n",
        "**Example: Predicting Hospital Readmission Rates using Linear Regression**\n",
        "\n",
        "**Dataset:**\n",
        "Suppose we have a dataset containing the following features for a group of patients:\n",
        "\n",
        "1. Age: The age of the patient (numeric).\n",
        "2. BMI: Body Mass Index, a measure of body fat based on height and weight (numeric).\n",
        "3. Blood Pressure: Systolic and diastolic blood pressure readings (numeric).\n",
        "4. Diabetes: Binary variable indicating whether the patient has diabetes (0 = No, 1 = Yes).\n",
        "5. Heart Disease: Binary variable indicating whether the patient has a history of heart disease (0 = No, 1 = Yes).\n",
        "6. Length of Stay: The number of days the patient stayed in the hospital during their last admission (numeric).\n",
        "7. Number of Previous Admissions: The number of times the patient has been admitted to the hospital in the past (numeric).\n",
        "8. Readmission Rate: The target variable, representing the percentage of patients readmitted within 30 days of discharge (numeric).\n",
        "\n",
        "**Objective:**\n",
        "We want to build a linear regression model to predict the readmission rate of patients based on their demographic and medical features.\n",
        "\n",
        "**Steps:**\n",
        "\n",
        "1. **Data Preprocessing:**\n",
        "   - Handle missing values: Deal with any missing data in the dataset, either by imputing missing values or removing incomplete records.\n",
        "   - Feature Scaling: Scale the features, if necessary, to ensure all variables are on a similar scale. For example, normalize BMI, blood pressure, and length of stay.\n",
        "\n",
        "2. **Data Splitting:**\n",
        "   - Split the dataset into a training set and a test set. The training set will be used to train the linear regression model, while the test set will be used to evaluate its performance.\n",
        "\n",
        "3. **Linear Regression Model Training:**\n",
        "   - Train a linear regression model using the training data. The model will learn the coefficients (weights) for each feature, which represent the relationship between the features and the target variable (readmission rate).\n",
        "\n",
        "4. **Model Evaluation:**\n",
        "   - Evaluate the trained linear regression model using the test data. Calculate metrics such as Mean Squared Error (MSE), R-squared, or Mean Absolute Error (MAE) to assess the model's performance.\n",
        "\n",
        "5. **Feature Importance:**\n",
        "   - Analyze the coefficients of the linear regression model to identify the most influential features on readmission rates. This helps healthcare providers understand which factors have the most significant impact on readmission risk.\n",
        "\n",
        "6. **Prediction and Insights:**\n",
        "   - Use the trained linear regression model to predict readmission rates for new patients based on their medical and demographic information.\n",
        "   - Provide insights and recommendations to healthcare providers based on the model's findings. For example, if the length of stay is a significant predictor of readmission rates, healthcare providers may focus on optimizing patient care during hospital stays to reduce the risk of readmission.\n",
        "\n",
        "By employing a linear regression model in this healthcare setting, we can gain valuable insights into the factors affecting hospital readmission rates and develop strategies to improve patient care and outcomes."
      ],
      "metadata": {
        "id": "hGaNNWkaDqDY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FAQ"
      ],
      "metadata": {
        "id": "8wb9CG7PYnne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. What is Linear Regression, and how does it work?\n",
        "   Linear Regression is a statistical method used to model the relationship between a dependent variable and one or more independent variables by fitting a linear equation to the observed data. It tries to find the best-fitting straight line through the data points, minimizing the sum of the squared differences between the predicted and actual values.\n",
        "\n",
        "2. When should I use Linear Regression?\n",
        "   Linear Regression is commonly used when there is a linear relationship between the dependent and independent variables. It is suitable for predicting continuous numeric values and understanding the strength and direction of the relationships between variables.\n",
        "\n",
        "3. How is the performance of a Linear Regression model measured?\n",
        "   The performance of a Linear Regression model is typically evaluated using metrics such as Mean Squared Error (MSE), Root Mean Squared Error (RMSE), Mean Absolute Error (MAE), and R-squared (R2) value, which indicates the proportion of variance in the dependent variable that is predictable from the independent variables.\n",
        "\n",
        "4. Can Linear Regression handle categorical variables?\n",
        "   Linear Regression is designed for continuous numeric variables. However, categorical variables can be incorporated using techniques like one-hot encoding or dummy variable encoding to convert them into numerical representations.\n",
        "\n",
        "5. What are the assumptions of Linear Regression?\n",
        "   Linear Regression relies on certain assumptions, including linearity (the relationship between variables is linear), independence of errors (residuals), normality of errors, constant variance (homoscedasticity), and no multicollinearity (no strong correlation between independent variables).\n",
        "\n",
        "6. Is it possible to have negative R-squared values in Linear Regression?\n",
        "   Yes, it is possible to have negative R-squared values in Linear Regression. This occurs when the model's fit is worse than the average of the dependent variable's sample mean. It indicates that the model is not capturing the variation in the data and might not be suitable for the given dataset.\n",
        "\n",
        "7. What is the difference between Simple Linear Regression and Multiple Linear Regression?\n",
        "   Simple Linear Regression involves one independent variable and one dependent variable, fitting a straight line to the data. On the other hand, Multiple Linear Regression deals with multiple independent variables to predict a single dependent variable using a multi-dimensional hyperplane.\n",
        "\n",
        "8. Can outliers affect the performance of a Linear Regression model?\n",
        "   Yes, outliers can significantly influence the performance of a Linear Regression model. Outliers can pull the regression line away from the majority of data points, affecting the model's accuracy and making it less reliable for making predictions.\n",
        "\n",
        "9. Is it possible to use Linear Regression for non-linear relationships?\n",
        "   Although Linear Regression assumes a linear relationship between variables, it is possible to model certain non-linear relationships using techniques like polynomial regression, log transformation, or introducing interaction terms to capture more complex patterns.\n",
        "\n",
        "10. How can multicollinearity impact the interpretation of a Linear Regression model?\n",
        "    Multicollinearity occurs when two or more independent variables are highly correlated. This can lead to issues in the model interpretation, as it becomes challenging to distinguish the individual effects of these variables on the dependent variable. It can also cause instability in the model's coefficients and predictions."
      ],
      "metadata": {
        "id": "r6odQcqJ5W2u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quiz"
      ],
      "metadata": {
        "id": "YVLEEpgUf2z5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Question 1:** What type of relationship does linear regression model capture?\n",
        "\n",
        "A) Non-linear relationships  \n",
        "B) Exponential relationships  \n",
        "C) Linear relationships  \n",
        "D) Complex relationships  \n",
        "\n",
        "**Question 2:** In a simple linear regression equation, what does the slope (m) represent?\n",
        "\n",
        "A) The intercept on the y-axis  \n",
        "B) The intercept on the x-axis  \n",
        "C) The rate of change in y for a unit change in x  \n",
        "D) The rate of change in x for a unit change in y  \n",
        "\n",
        "**Question 3:** Which of the following methods is commonly used to estimate the parameters in a linear regression model?\n",
        "\n",
        "A) Mean Squared Error (MSE)  \n",
        "B) Mean Absolute Deviation (MAD)  \n",
        "C) Median Absolute Deviation (MedAD)  \n",
        "D) Root Mean Squared Error (RMSE)  \n",
        "\n",
        "**Question 4:** What is the goal of the linear regression model?\n",
        "\n",
        "A) To make accurate predictions on new data  \n",
        "B) To perfectly fit the training data  \n",
        "C) To minimize the number of features used  \n",
        "D) To create complex, non-linear relationships  \n",
        "\n",
        "**Question 5:** If the correlation coefficient between two variables is close to -1, what does this indicate?\n",
        "\n",
        "A) Strong positive correlation  \n",
        "B) Weak positive correlation  \n",
        "C) Strong negative correlation  \n",
        "D) Weak negative correlation  \n",
        "\n",
        "**Question 6:** What is the main assumption of linear regression regarding the residuals?\n",
        "\n",
        "A) Residuals should have a normal distribution  \n",
        "B) Residuals should have a uniform distribution  \n",
        "C) Residuals should be perfectly correlated with the independent variable  \n",
        "D) Residuals are not important in linear regression  \n",
        "\n",
        "**Question 7:** How is the goodness of fit typically evaluated in linear regression?\n",
        "\n",
        "A) Using the coefficient of determination (R-squared)  \n",
        "B) Counting the number of features used  \n",
        "C) Comparing the mean of predicted values with the mean of actual values  \n",
        "D) Using the p-value of the intercept  \n",
        "\n",
        "**Question 8:** What does multicollinearity refer to in the context of linear regression?\n",
        "\n",
        "A) When the residuals are correlated with each other  \n",
        "B) When there is only one independent variable  \n",
        "C) When the independent variables are correlated with each other  \n",
        "D) When the dependent variable is correlated with the independent variables  \n",
        "\n",
        "**Question 9:** In linear regression, if the p-value associated with a coefficient is very high (e.g., 0.8), what does it imply?\n",
        "\n",
        "A) The coefficient is statistically significant  \n",
        "B) The coefficient is not statistically significant  \n",
        "C) The coefficient is equal to zero  \n",
        "D) The coefficient is negative  \n",
        "\n",
        "**Question 10:** Which of the following is a potential drawback of linear regression?\n",
        "\n",
        "A) It cannot handle non-linear relationships  \n",
        "B) It always results in overfitting  \n",
        "C) It is immune to outliers  \n",
        "D) It requires a large number of observations  \n",
        "\n",
        "**Answers:**\n",
        "\n",
        "1. C) Linear relationships\n",
        "2. C) The rate of change in y for a unit change in x\n",
        "3. A) Mean Squared Error (MSE)\n",
        "4. A) To make accurate predictions on new data\n",
        "5. C) Strong negative correlation\n",
        "6. A) Residuals should have a normal distribution\n",
        "7. A) Using the coefficient of determination (R-squared)\n",
        "8. C) When the independent variables are correlated with each other\n",
        "9. B) The coefficient is not statistically significant\n",
        "10. A) It cannot handle non-linear relationships"
      ],
      "metadata": {
        "id": "MacVwsCwf5sA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Ideas"
      ],
      "metadata": {
        "id": "hWoOdYPXylcx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **Predicting Hospital Readmissions**:\n",
        "   - **Dataset**: Patient data including age, gender, medical history, previous hospitalizations, and medication.\n",
        "   - **Task**: Predict the likelihood of a patient being readmitted within 30 days after discharge.\n",
        "\n",
        "2. **Estimation of Medical Expenses**:\n",
        "   - **Dataset**: Personal health statistics (smoking, BMI, age, gender) and associated medical expenses.\n",
        "   - **Task**: Predict future medical expenses based on individual health metrics.\n",
        "\n",
        "3. **Predicting Recovery Time Post Surgery**:\n",
        "   - **Dataset**: Surgery type, age, gender, medical history, and actual recovery time.\n",
        "   - **Task**: Predict the recovery time needed for future patients undergoing similar surgeries.\n",
        "\n",
        "4. **Estimating Blood Sugar Levels**:\n",
        "   - **Dataset**: Food intake, physical activity, medications, previous blood sugar readings.\n",
        "   - **Task**: Predict future blood sugar levels given a set of inputs.\n",
        "\n",
        "5. **Predicting Disease Progression**:\n",
        "   - **Dataset**: Patient data including age, lifestyle factors, medication, and disease progression markers over time.\n",
        "   - **Task**: Predict the progression rate of a disease (e.g., Alzheimer’s, Parkinson’s) for an individual.\n",
        "\n",
        "6. **Determining Patient Wait Times**:\n",
        "   - **Dataset**: Hospital admittance rates, time of day, staff on duty, and historical wait times.\n",
        "   - **Task**: Predict patient wait times in the emergency room or outpatient clinics.\n",
        "\n",
        "7. **Predicting Birth Weights**:\n",
        "   - **Dataset**: Maternal health data, nutrition, prenatal care details, and birth weights of newborns.\n",
        "   - **Task**: Predict the birth weight of newborns based on maternal factors.\n",
        "\n",
        "8. **Estimation of Medication Dosage**:\n",
        "   - **Dataset**: Patient's weight, age, organ functions (like liver, kidney), and current medications.\n",
        "   - **Task**: Predict the optimal medication dosage to achieve desired therapeutic effects without toxicity.\n",
        "\n",
        "9. **Bone Density Prediction**:\n",
        "   - **Dataset**: Patient’s age, gender, dietary habits, exercise habits, and bone density scans.\n",
        "   - **Task**: Predict the future bone density of a patient and assess osteoporosis risk.\n",
        "\n",
        "10. **Predicting Length of Hospital Stay**:\n",
        "    - **Dataset**: Type of illness, severity, age, gender, and historical length of stay data.\n",
        "    - **Task**: Predict how long a patient will need to remain in the hospital.\n",
        "\n",
        "11. **Estimating the Impact of Lifestyle on Lifespan**:\n",
        "    - **Dataset**: Dietary habits, exercise habits, sleep patterns, stress levels, and age at death or current age.\n",
        "    - **Task**: Predict the potential lifespan of an individual based on their lifestyle habits.\n",
        "\n",
        "12. **Assessing Mental Health Outcomes**:\n",
        "    - **Dataset**: Therapy methods, medication, lifestyle factors, severity of symptoms, and improvement scores over time.\n",
        "    - **Task**: Predict the effectiveness of various therapeutic interventions on mental health outcomes.\n"
      ],
      "metadata": {
        "id": "dDWfbL0wym8n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practical Example"
      ],
      "metadata": {
        "id": "j5PYLzdeDbv3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Linear regression is a simple yet powerful algorithm used in predictive analytics. Here's an example using a real-world health dataset: predicting a person's weight based on their height.\n",
        "\n",
        "While this is a simplified case (in reality, the relationship between height and weight can be influenced by various factors), it provides a clear illustration of how to use linear regression.\n",
        "\n",
        "Let's assume we have the following sample data:\n",
        "\n",
        "| Height (cm) | Weight (kg) |\n",
        "|-------------|-------------|\n",
        "| 150         | 45          |\n",
        "| 160         | 60          |\n",
        "| 170         | 70          |\n",
        "| 180         | 77          |\n",
        "| 190         | 85          |\n",
        "\n",
        "1. First, let's import necessary libraries:\n",
        "```python\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import LinearRegression\n",
        "```\n",
        "\n",
        "2. Let's create our X (features) and y (target) datasets:\n",
        "```python\n",
        "X = np.array([150, 160, 170, 180, 190]).reshape(-1, 1)\n",
        "y = np.array([45, 60, 70, 77, 85])\n",
        "```\n",
        "\n",
        "3. Splitting the data into training and testing (For simplicity, we won't do this here, but it's generally good practice).\n",
        "\n",
        "4. Creating and training the model:\n",
        "```python\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "```\n",
        "\n",
        "5. Getting predictions:\n",
        "```python\n",
        "height_new = np.array([165, 175]).reshape(-1, 1)\n",
        "weight_predicted = model.predict(height_new)\n",
        "print(weight_predicted)\n",
        "```\n",
        "\n",
        "6. Visualizing the linear regression:\n",
        "```python\n",
        "plt.scatter(X, y, color='blue')\n",
        "plt.plot(X, model.predict(X), color='red')\n",
        "plt.xlabel('Height (cm)')\n",
        "plt.ylabel('Weight (kg)')\n",
        "plt.title('Weight Prediction based on Height')\n",
        "plt.show()\n",
        "```\n",
        "\n",
        "When you run this code, you'll see the sample data points as blue dots, and the predicted linear relationship between height and weight as a red line.\n",
        "\n",
        "Remember, always ensure you have a sufficiently large dataset for training the model to get accurate predictions. Also, the above example assumes a direct linear relationship between height and weight which might not be the case in real-world scenarios due to other factors like body composition, genetics, etc. Always validate your model's assumptions and its performance on test data."
      ],
      "metadata": {
        "id": "KKoilT73yGYY"
      }
    }
  ]
}