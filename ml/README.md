# Machine Learning Models

The models can be grouped based on their characteristics and applications. Here are the groups:

**Supervised Learning Models:**
- Linear Regression
- Logistic Regression
- Decision Trees
- Random Forests
- Support Vector Machines (SVM)
- k-Nearest Neighbors (k-NN)
- Naive Bayes
- Gradient Boosting Machines (GBM)
- XGBoost (Extreme Gradient Boosting)
- LightGBM (Light Gradient Boosting Machine)
- CatBoost (Categorical Boosting)
- Ridge Regression (L2 Regularization)
- Lasso Regression (L1 Regularization)
- Ridge Classification (Logistic Regression with L2 Regularization)
- Lasso Classification (Logistic Regression with L1 Regularization)

**Unsupervised Learning Models:**
- Principal Component Analysis (PCA)
- k-Means Clustering
- Hierarchical Clustering
- Gaussian Mixture Models (GMM)

**Other Techniques:**
- Decision Boundary Estimation (DBE)
- Elastic Net

Note: Some models could fit into multiple categories depending on how they are used. For instance, logistic regression can be considered both a supervised learning model for classification and a regularization technique when used with L1 or L2 regularization. Similarly, Ridge and Lasso Regression can be seen as both supervised learning models and regularization techniques.
