{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP+ARFBuZ+XmeBHNuFvG7EP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cloudpedagogy/AI-models/blob/main/ml/Support_Vector_Machines_(SVM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Support Vector Machines (SVM) Model Background"
      ],
      "metadata": {
        "id": "2_Oeyyd9AuMu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support Vector Machines (SVM) is a popular supervised machine learning algorithm used for classification and regression tasks. It works by finding the optimal hyperplane that best separates data points of different classes. SVM is effective in both linearly separable and non-linearly separable datasets, thanks to the use of the kernel trick, which transforms the data into a higher-dimensional space.\n",
        "\n",
        "Here are some pros and cons of Support Vector Machines:\n",
        "\n",
        "**Pros**:\n",
        "1. Effective in high-dimensional spaces: SVM performs well even when the number of features is greater than the number of samples, making it suitable for complex datasets.\n",
        "2. Versatile kernel functions: SVM can use various kernel functions (e.g., linear, polynomial, radial basis function) to handle non-linear data, giving it flexibility in capturing complex relationships.\n",
        "3. Robust to overfitting: SVM tries to maximize the margin between classes, which reduces the risk of overfitting, especially in cases with good separation between classes.\n",
        "4. Global solution: SVM's objective function is convex, ensuring it always finds the global optimal solution, unlike some other algorithms sensitive to initialization.\n",
        "5. Works well with small datasets: SVM can still perform well with a limited number of samples, making it suitable for problems with a relatively small training set.\n",
        "\n",
        "**Cons**:\n",
        "1. Computationally intensive: SVM can be computationally expensive, especially with large datasets or complex kernel functions, which may lead to longer training times.\n",
        "2. Sensitive to hyperparameters: The choice of the kernel and its parameters can significantly affect the performance of SVM. Finding the right hyperparameters can be challenging and might require tuning.\n",
        "3. Memory-intensive: The model's memory requirements increase with the number of support vectors, which can be a concern for large datasets.\n",
        "4. Limited interpretability: SVM models are not as easily interpretable as some other algorithms, such as decision trees or logistic regression.\n",
        "5. Binary classifier: SVM is inherently a binary classifier, although there are techniques like one-vs-all and one-vs-one for multi-class problems.\n",
        "\n",
        "**When to use SVM**:\n",
        "1. Small to medium-sized datasets: SVM can be a good choice when the dataset is not too large, as it can still perform well with a limited number of samples.\n",
        "2. High-dimensional data: SVM can handle high-dimensional feature spaces effectively, making it suitable for problems with many features.\n",
        "3. Non-linear data: When the data is not linearly separable, SVM with appropriate kernel functions can capture complex relationships.\n",
        "4. Text classification and sentiment analysis: SVM has been widely used in natural language processing tasks with text data.\n",
        "5. Image classification: SVM has been used for image recognition and object detection tasks, especially when combined with powerful feature extraction techniques.\n",
        "\n",
        "However, with the advent of more advanced deep learning algorithms like convolutional neural networks (CNNs) and recurrent neural networks (RNNs), SVM is not always the first choice for large-scale, complex tasks. It is still a relevant and valuable tool in many scenarios, but the choice of algorithm ultimately depends on the specific problem, data, and resources available."
      ],
      "metadata": {
        "id": "1MsAVBdu8YwW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code Example"
      ],
      "metadata": {
        "id": "3o5S6wU_bChw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Load the Iris dataset (you can replace this with your own dataset)\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create the SVM model\n",
        "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "\n",
        "# Train the SVM model on the training data\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "# Display the classification report\n",
        "target_names = iris.target_names\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n"
      ],
      "metadata": {
        "id": "lj1aHl1Iy0vS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Code breakdown"
      ],
      "metadata": {
        "id": "I1wjpF-F0ld8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Step 1: Import necessary libraries\n",
        "```python\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "```\n",
        "\n",
        "Step 2: Load the Iris dataset\n",
        "```python\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "```\n",
        "In this step, the Iris dataset is loaded from scikit-learn's built-in datasets. `X` contains the features (four numerical attributes) of the Iris samples, and `y` contains the target variable (the species of Iris plants).\n",
        "\n",
        "Step 3: Split the dataset into training and testing sets\n",
        "```python\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "```\n",
        "The `train_test_split` function is used to split the dataset into training and testing sets. Here, 80% of the data is used for training (`X_train` and `y_train`), and 20% is used for testing (`X_test` and `y_test`). The `random_state` parameter is set to 42 to ensure reproducibility of the split.\n",
        "\n",
        "Step 4: Create the SVM model\n",
        "```python\n",
        "svm_model = SVC(kernel='linear', C=1.0, random_state=42)\n",
        "```\n",
        "An instance of the Support Vector Machine (SVM) model is created using the `SVC` class from scikit-learn. In this case, a linear kernel is used (`kernel='linear'`), and the regularization parameter `C` is set to 1.0. The `random_state` parameter is set to 42 for reproducibility.\n",
        "\n",
        "Step 5: Train the SVM model on the training data\n",
        "```python\n",
        "svm_model.fit(X_train, y_train)\n",
        "```\n",
        "The SVM model is trained on the training data (`X_train` and `y_train`) using the `fit` method.\n",
        "\n",
        "Step 6: Make predictions on the test set\n",
        "```python\n",
        "y_pred = svm_model.predict(X_test)\n",
        "```\n",
        "The trained SVM model is used to make predictions on the test set (`X_test`) using the `predict` method. The predicted target values are stored in `y_pred`.\n",
        "\n",
        "Step 7: Evaluate the model\n",
        "```python\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy: {accuracy:.2f}\")\n",
        "```\n",
        "The accuracy of the model is calculated by comparing the predicted target values (`y_pred`) with the true target values of the test set (`y_test`). The `accuracy_score` function from scikit-learn's `metrics` module is used for this calculation. The accuracy is then printed to the console.\n",
        "\n",
        "Step 8: Display the classification report\n",
        "```python\n",
        "target_names = iris.target_names\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_test, y_pred, target_names=target_names))\n",
        "```\n",
        "A classification report is generated to provide a more detailed evaluation of the model's performance. The `classification_report` function from scikit-learn's `metrics` module is used for this purpose. The classification report includes metrics such as precision, recall, F1-score, and support for each class (species of Iris plants). The `target_names` parameter is set to the class names (setosa, versicolor, virginica) for better readability.\n",
        "\n",
        "That's the step-by-step explanation of the code. It demonstrates how to train an SVM model on the Iris dataset, make predictions, calculate accuracy, and generate a classification report for performance evaluation."
      ],
      "metadata": {
        "id": "eWvhiEH22jZK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Real world application"
      ],
      "metadata": {
        "id": "r2ZM3UOy18Mp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A real-world example of Support Vector Machines (SVM) in a healthcare setting is the classification of medical images for disease detection and diagnosis. SVM can be applied to analyze various types of medical images, such as X-rays, MRIs, CT scans, and histopathological slides, to aid in the early detection and accurate diagnosis of diseases.\n",
        "\n",
        "For instance, let's consider the application of SVM in detecting breast cancer from mammography images:\n",
        "\n",
        "Breast Cancer Detection using SVM:\n",
        "\n",
        "1. Data Collection: A dataset is created, consisting of mammography images from patients with both diagnosed breast cancer (positive samples) and healthy individuals (negative samples). Each image is labeled with the corresponding diagnosis.\n",
        "\n",
        "2. Image Preprocessing: The mammography images undergo preprocessing steps to enhance the quality and remove noise. This may involve resizing, normalization, and image filtering.\n",
        "\n",
        "3. Feature Extraction: Key features are extracted from each mammography image to represent relevant characteristics of the tissue and potential cancerous regions. These features could include texture, intensity, shape, or other image-based characteristics.\n",
        "\n",
        "4. Feature Selection: Not all features extracted may be relevant for breast cancer detection. Feature selection techniques are applied to identify the most informative and discriminative features.\n",
        "\n",
        "5. Training the SVM Model: The selected features and their corresponding labels (cancer or non-cancer) are used to train the SVM model. SVM learns to create a decision boundary that best separates the two classes in the feature space.\n",
        "\n",
        "6. Model Evaluation: The trained SVM model is evaluated on a separate set of mammography images that it has not seen during training. The accuracy, sensitivity, specificity, and other performance metrics are calculated to assess the model's effectiveness in classifying breast cancer cases correctly.\n",
        "\n",
        "7. Deployment: Once the SVM model has been trained and evaluated satisfactorily, it can be deployed in a clinical setting to assist radiologists and physicians in interpreting mammography images and improving the accuracy of breast cancer detection.\n",
        "\n",
        "Using SVM in this context allows for effective classification of mammography images into benign or malignant cases, thus aiding in early detection and potentially saving lives through timely intervention and treatment.\n",
        "\n",
        "It's important to note that SVM is just one of the many machine learning techniques applied in healthcare settings. The choice of the most suitable algorithm depends on the nature of the data, the specific task, and the availability of resources. Additionally, real-world applications may require extensive validation and regulatory approval before being implemented in clinical practice."
      ],
      "metadata": {
        "id": "ZicrBQ5EIx8p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# FAQ"
      ],
      "metadata": {
        "id": "-X5mApRo3ZsC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. What is a Support Vector Machine (SVM)?\n",
        "   - SVM is a powerful supervised machine learning algorithm used for classification and regression tasks. It finds the optimal hyperplane that best separates the data points of different classes in a high-dimensional space.\n",
        "\n",
        "2. How does SVM handle non-linear data?\n",
        "   - SVM can handle non-linear data by using kernel functions such as polynomial, radial basis function (RBF), or sigmoid to map the data into a higher-dimensional space where it becomes linearly separable.\n",
        "\n",
        "3. What is the significance of \"Support Vectors\" in SVM?\n",
        "   - Support Vectors are the data points that lie closest to the decision boundary (hyperplane) and determine its position. These points are crucial as they have the most influence on the SVM's performance.\n",
        "\n",
        "4. What is the \"C\" parameter in SVM?\n",
        "   - The \"C\" parameter in SVM is a regularization term that controls the trade-off between maximizing the margin and minimizing the classification error. A smaller \"C\" value allows a larger margin but may allow some misclassifications, while a larger \"C\" value tries to classify all data points correctly but may lead to overfitting.\n",
        "\n",
        "5. How does SVM handle imbalanced datasets?\n",
        "   - SVM can handle imbalanced datasets by using different class weights. By assigning higher weights to the minority class, SVM focuses more on correctly classifying the minority class while still considering the majority class.\n",
        "\n",
        "6. What are the advantages of SVM over other algorithms?\n",
        "   - SVM can handle high-dimensional data efficiently and is effective even with a small number of samples. It also provides excellent generalization and can handle non-linear data using kernel tricks.\n",
        "\n",
        "7. What are some popular kernel functions used in SVM?\n",
        "   - Some popular kernel functions used in SVM are:\n",
        "     - Linear Kernel: K(x, y) = x^T * y\n",
        "     - Polynomial Kernel: K(x, y) = (gamma * x^T * y + coef0)^degree\n",
        "     - Radial Basis Function (RBF) Kernel: K(x, y) = exp(-gamma * ||x - y||^2)\n",
        "     - Sigmoid Kernel: K(x, y) = tanh(gamma * x^T * y + coef0)\n",
        "\n",
        "8. Can SVM be used for regression tasks as well?\n",
        "   - Yes, SVM can be used for regression tasks, and it is known as Support Vector Regression (SVR). SVR finds a hyperplane that best fits the data points within a specified margin, aiming to minimize the error between predicted and actual values.\n",
        "\n",
        "9. What are some real-world applications of SVM?\n",
        "   - SVM has been successfully applied in various domains, including text classification, image recognition, bioinformatics, finance, and medical diagnosis.\n",
        "\n",
        "10. Does SVM suffer from the \"Curse of Dimensionality\"?\n",
        "    - SVM's performance can degrade when dealing with very high-dimensional data, as the number of support vectors may increase significantly, leading to longer training times and potential overfitting. However, kernel functions can help address this issue by transforming the data into a higher-dimensional space only when necessary.\n",
        "\n",
        "Remember that these FAQs provide a general overview of SVM and its applications. In-depth knowledge and understanding may require further study and practical experience with the algorithm."
      ],
      "metadata": {
        "id": "XSL6Fipl8sf4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Quiz"
      ],
      "metadata": {
        "id": "AEbH4cwQi_5k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Questions**\n",
        "\n",
        "1. What is the main objective of a Support Vector Machine?\n",
        "a) Regression\n",
        "b) Classification\n",
        "c) Clustering\n",
        "d) Dimensionality reduction\n",
        "\n",
        "2. SVM aims to find a hyperplane that:\n",
        "a) Maximizes the margin between classes\n",
        "b) Minimizes the margin between classes\n",
        "c) Maximizes the number of support vectors\n",
        "d) Maximizes the number of misclassified samples\n",
        "\n",
        "3. What is the term used to describe the data points that lie closest to the decision boundary in an SVM?\n",
        "a) Decision points\n",
        "b) Margin vectors\n",
        "c) Support vectors\n",
        "d) Critical points\n",
        "\n",
        "4. In an SVM, what is the margin?\n",
        "a) The distance between the support vectors and the decision boundary\n",
        "b) The distance between the data points of different classes\n",
        "c) The distance between the origin and the support vectors\n",
        "d) The distance between the centroid and the decision boundary\n",
        "\n",
        "5. Which kernel function is commonly used to handle nonlinear classification problems in SVM?\n",
        "a) Linear kernel\n",
        "b) Polynomial kernel\n",
        "c) Gaussian (RBF) kernel\n",
        "d) Sigmoid kernel\n",
        "\n",
        "6. What is the purpose of the regularization parameter (C) in SVM?\n",
        "a) To control the width of the margin\n",
        "b) To adjust the balance between correct classifications and margin maximization\n",
        "c) To control the trade-off between bias and variance\n",
        "d) To determine the number of support vectors\n",
        "\n",
        "7. Which of the following SVM kernels is most suitable for text classification tasks?\n",
        "a) Linear kernel\n",
        "b) Polynomial kernel\n",
        "c) Gaussian (RBF) kernel\n",
        "d) Sigmoid kernel\n",
        "\n",
        "8. In which scenario would an SVM likely suffer from the \"curse of dimensionality\"?\n",
        "a) When dealing with a large number of features\n",
        "b) When the dataset is too small\n",
        "c) When the classes are well-separated\n",
        "d) When using a linear kernel\n",
        "\n",
        "9. SVM is a binary classification algorithm. How can it be extended for multiclass classification?\n",
        "a) By training multiple binary classifiers and combining their outputs\n",
        "b) By using a special multiclass kernel\n",
        "c) By converting the problem into a regression task\n",
        "d) SVM cannot be used for multiclass classification\n",
        "\n",
        "10. Which of the following is a disadvantage of SVM?\n",
        "a) High computational complexity\n",
        "b) Works well with small datasets only\n",
        "c) Doesn't handle nonlinear data\n",
        "d) Doesn't provide probability estimates\n",
        "\n",
        "**Answers:**\n",
        "1. b) Classification\n",
        "2. a) Maximizes the margin between classes\n",
        "3. c) Support vectors\n",
        "4. a) The distance between the support vectors and the decision boundary\n",
        "5. c) Gaussian (RBF) kernel\n",
        "6. b) To adjust the balance between correct classifications and margin maximization\n",
        "7. c) Gaussian (RBF) kernel\n",
        "8. a) When dealing with a large number of features\n",
        "9. a) By training multiple binary classifiers and combining their outputs\n",
        "10. a) High computational complexity"
      ],
      "metadata": {
        "id": "N9EfbSrPjB0k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project Ideas"
      ],
      "metadata": {
        "id": "bv3man-120Su"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "1. **Disease Prediction**\n",
        "   - **Diabetes Prediction:** Use the Pima Indians Diabetes Database to predict the onset of diabetes based on diagnostic measures.\n",
        "   - **Heart Disease Prediction:** Use a dataset like the Cleveland Heart Disease dataset to predict the presence of heart disease.\n",
        "\n",
        "2. **Medical Image Analysis**\n",
        "   - **Tumor Detection:** Analyze MRI or CT scan images to detect and classify tumors as malignant or benign.\n",
        "   - **Retinal Disease Classification:** Identify diseases like Diabetic Retinopathy in eye images.\n",
        "\n",
        "3. **Genomic Data Analysis**\n",
        "   - **Gene Expression Classification:** Use SVM to classify tissue samples based on their gene expression profiles.\n",
        "   - **Protein Structure Prediction:** Predict the functional class of a protein based on its sequence.\n",
        "\n",
        "4. **Medical Text Analysis**\n",
        "   - **Electronic Health Record (EHR) Analysis:** Predict patient outcomes or classify diseases based on text notes from EHRs.\n",
        "   - **Medical Literature Classification:** Classify medical papers based on their content for easy indexing and retrieval.\n",
        "\n",
        "5. **Patient Readmission Prediction**\n",
        "   - Analyze patient data to predict if they might be readmitted within 30 days of discharge.\n",
        "\n",
        "6. **Drug Response Prediction**\n",
        "   - Predict how a patient will respond to a drug based on their genetic makeup or other health parameters.\n",
        "\n",
        "7. **Mental Health Analysis**\n",
        "   - **Depression Detection:** Use features like text from social media, speech patterns, etc., to detect early signs of depression.\n",
        "   - **Stress Level Analysis:** Based on physiological parameters, predict the stress levels of individuals.\n",
        "\n",
        "8. **Wearable Device Data Analysis**\n",
        "   - **Activity Classification:** Classify different types of activities or movements (e.g., walking, running, falling) based on data from wearables.\n",
        "   - **Sleep Stage Prediction:** Analyze sleep data to classify different sleep stages.\n",
        "\n",
        "9. **Outbreak Prediction**\n",
        "   - Predict potential outbreaks or the spread of diseases based on regional healthcare reports or other related data.\n",
        "\n",
        "10. **Optimizing Treatment Plans**\n",
        "   - Based on patient data, predict which treatment plan might be most effective for certain conditions or diseases.\n",
        "\n",
        "11. **Early Warning Systems**\n",
        "   - **Sepsis Detection:** Use patient vitals and laboratory test results to predict the onset of sepsis.\n",
        "   - **ICU Transfer Prediction:** Predict if a patient will need to be transferred to the ICU based on their current data.\n",
        "\n",
        "12. **Epidemiological Study**\n",
        "   - **Disease Mapping:** Use SVM to predict the spread or emergence of diseases in certain geographic areas based on factors like climate, population density, etc.\n"
      ],
      "metadata": {
        "id": "KwrQoPbN22PD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Practical Example"
      ],
      "metadata": {
        "id": "gqJSApeUEbzb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A basic example of how to implement a Support Vector Machines (SVM) model using real-world health data. In this example, we'll use the famous \"Breast Cancer Wisconsin\" dataset, which is available in the scikit-learn library. This dataset contains features calculated from a digitized image of a fine needle aspirate (FNA) of a breast mass, and the goal is to classify tumors as malignant or benign.\n",
        "\n",
        "Here's a step-by-step example using Python and scikit-learn:"
      ],
      "metadata": {
        "id": "g44iItCI4i4P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import numpy as np\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the Breast Cancer Wisconsin dataset\n",
        "data = load_breast_cancer()\n",
        "X = data.data  # Features\n",
        "y = data.target  # Target labels (0: malignant, 1: benign)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Initialize the SVM model\n",
        "svm_model = SVC(kernel='linear', C=1.0)  # Linear kernel, you can experiment with other kernels\n",
        "\n",
        "# Train the SVM model on the training data\n",
        "svm_model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = svm_model.predict(X_test)\n",
        "\n",
        "# Calculate accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "id": "96m-hU3y4eVB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "In this example:\n",
        "- We import the necessary libraries, including scikit-learn for the dataset, model, and evaluation.\n",
        "- We load the Breast Cancer Wisconsin dataset and split it into training and testing sets using the `train_test_split` function.\n",
        "- We create an instance of the SVM model using the `SVC` class with a linear kernel and a regularization parameter (`C`).\n",
        "- We train the model on the training data using the `fit` method.\n",
        "- We make predictions on the test data using the trained model.\n",
        "- Finally, we calculate and print the accuracy of the model's predictions.\n",
        "\n",
        "Keep in mind that this is a basic example, and SVM models often benefit from preprocessing steps, parameter tuning, and more advanced techniques. Also, real-world health data may require additional considerations like data privacy and ethical considerations."
      ],
      "metadata": {
        "id": "7-24g4Oq4r-S"
      }
    }
  ]
}